<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>周阳七天Hadoop | MxRanger's Blog</title><meta name="keywords" content="大数据"><meta name="author" content="慕·歌"><meta name="copyright" content="慕·歌"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一、Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="周阳七天Hadoop">
<meta property="og:url" content="http://example.com/2019/04/30/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/index.html">
<meta property="og:site_name" content="MxRanger&#39;s Blog">
<meta property="og:description" content="一、Hadoop">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/hadoop.jpg">
<meta property="article:published_time" content="2019-04-30T11:50:40.000Z">
<meta property="article:modified_time" content="2021-06-19T03:00:45.217Z">
<meta property="article:author" content="慕·歌">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/hadoop.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2019/04/30/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '周阳七天Hadoop',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-06-19 11:00:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><style type="text/css">#toggle-sidebar {bottom: 80px}</style><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="MxRanger's Blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/images/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/book"><i class="fa-fw fa fa-book"></i><span> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/hadoop.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">MxRanger's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/book"><i class="fa-fw fa fa-book"></i><span> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">周阳七天Hadoop</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-04-30T11:50:40.000Z" title="发表于 2019-04-30 19:50:40">2019-04-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-19T03:00:45.217Z" title="更新于 2021-06-19 11:00:45">2021-06-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>64分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="周阳七天Hadoop"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="一、Hadoop"><a href="#一、Hadoop" class="headerlink" title="一、Hadoop"></a>一、Hadoop</h1><span id="more"></span>

<p>环境搭建 <a href="E:\md\Hadoop安装教程.md">跳转</a></p>
<blockquote>
<p>VMware的搭建原理：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552897717595.png" alt="1552897717595"><br>楼道的网络结构：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552897760170.png" alt="1552897760170"></p>
</blockquote>
<h2 id="1、HDFS-实现原理"><a href="#1、HDFS-实现原理" class="headerlink" title="1、HDFS 实现原理"></a>1、HDFS 实现原理</h2><h3 id="1、原理图如下："><a href="#1、原理图如下：" class="headerlink" title="1、原理图如下："></a>1、原理图如下：</h3><p><img src="http://img.mxranger.cn/Hadoop/hdfs%E5%8E%9F%E7%90%86%E5%9B%BE.png" alt="hdfs原理图"></p>
<p><strong>HDFS实现思想：</strong></p>
<ul>
<li>1、hdfs是通过分布式集群来存储文件，为客户端提供了便捷的访问方式，就是一个虚拟的目录结构。</li>
<li>2、文件存储到hdfs集群中去的时候时被切分成block的</li>
<li>3、文件的block存放在若干台datanode节点上</li>
<li>4、hdfs文件系统的文件与真实的block之间有映射关系，由namenode管理</li>
<li>5、每一个block在集群中会存储多个副本，好处是可以提高数据的可靠性，还可以提高访问的吞吐量</li>
</ul>
<h3 id="2、常用的shell命令"><a href="#2、常用的shell命令" class="headerlink" title="2、常用的shell命令"></a>2、常用的shell命令</h3><pre><code>1.0查看帮助
    hadoop fs -help &lt;cmd&gt;
1.1上传
    hadoop fs -put &lt;linux上文件&gt; &lt;hdfs上的路径&gt;
1.2查看文件内容
    hadoop fs -cat &lt;hdfs上的路径&gt;
1.3查看文件列表
    hadoop fs -ls /
1.4下载文件
    hadoop fs -get &lt;hdfs上的路径&gt; &lt;linux上文件&gt;
</code></pre>
<h3 id="3、HDFS的block切片为128M的原因"><a href="#3、HDFS的block切片为128M的原因" class="headerlink" title="3、HDFS的block切片为128M的原因"></a>3、HDFS的block切片为128M的原因</h3><h4 id="1、为什么HDFS中块（block）不能设置太大，也不能设置太小？"><a href="#1、为什么HDFS中块（block）不能设置太大，也不能设置太小？" class="headerlink" title="1、为什么HDFS中块（block）不能设置太大，也不能设置太小？"></a><strong>1、为什么HDFS中块（block）不能设置太大，也不能设置太小？</strong></h4><p>原理：</p>
<p>文件块越大，寻址时间越短，但磁盘传输时间越长；</p>
<p>文件块越小，寻址时间越长，但磁盘传输时间越短。</p>
<ol>
<li><p>如果块设置过大，</p>
<p>一方面，从磁盘传输数据的时间会明显大于寻址时间，导致程序在处理这块数据时，变得非常慢；</p>
<p>另一方面，mapreduce中的map任务通常一次只处理一个块中的数据，如果块过大运行速度也会很慢。</p>
</li>
<li><p>如果块设置过小，</p>
<p>一方面存放大量小文件会占用NameNode中大量内存来存储元数据，而NameNode的内存是有限的，不可取；</p>
<p>另一方面文件块过小，寻址时间增大，导致程序一直在找block的开始位置。</p>
</li>
</ol>
<p>因而，块适当设置大一些，减少寻址时间，那么传输一个由多个块组成的文件的时间主要取决于磁盘的传输速率。</p>
<h4 id="2、-HDFS中块（block）的大小为什么设置为128M？"><a href="#2、-HDFS中块（block）的大小为什么设置为128M？" class="headerlink" title="2、 HDFS中块（block）的大小为什么设置为128M？"></a><strong>2、 HDFS中块（block）的大小为什么设置为128M？</strong></h4><ol>
<li><p>HDFS中平均寻址时间大概为10ms；</p>
</li>
<li><p>经过前人的大量测试发现，寻址时间为传输时间的1%时，为最佳状态；</p>
<p>所以最佳传输时间为10ms/0.01=1000ms=1s</p>
</li>
<li><p>目前磁盘的传输速率普遍为100MB/s；</p>
<p>计算出最佳block大小：100MB/s x 1s = 100MB</p>
<p>所以我们设定block大小为128MB。</p>
</li>
</ol>
<p>ps：实际在工业生产中，磁盘传输速率为200MB/s时，一般设定block大小为256MB<br>     磁盘传输速率为400MB/s时，一般设定block大小为512MB</p>
<h3 id="4、HDFS-存储架构"><a href="#4、HDFS-存储架构" class="headerlink" title="4、HDFS 存储架构"></a>4、HDFS 存储架构</h3><p><img src="http://img.mxranger.cn/Hadoop/1552791136637.png" alt="1552791136637"></p>
<p>客户端只负责上传一份文件，由DN来复制block</p>
<h4 id="3-1、namenode工作原理"><a href="#3-1、namenode工作原理" class="headerlink" title="3.1、namenode工作原理"></a>3.1、namenode工作原理</h4><blockquote>
<p>​    是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求</p>
<p>文件包括：</p>
<p>1、fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息<br>2、edits:操作日志文件<br>3、fstime:保存最近一次checkpoint的时间<br>以上这些文件是保存在linux的文件系统中</p>
</blockquote>
<h5 id="1、元数据存储细节"><a href="#1、元数据存储细节" class="headerlink" title="1、元数据存储细节"></a>1、元数据存储细节</h5><p><img src="http://img.mxranger.cn/Hadoop/1552804690069.png" alt="1552804690069"></p>
<h5 id="1、元数据原理机制"><a href="#1、元数据原理机制" class="headerlink" title="1、元数据原理机制"></a>1、元数据原理机制</h5><p><img src="http://img.mxranger.cn/Hadoop/1552791211046.png" alt="1552791211046"></p>
<h5 id="2、读请求"><a href="#2、读请求" class="headerlink" title="2、读请求"></a>2、读请求</h5><p>Namenode始终在内存中保存metedata（元数据），用于处理“读请求”</p>
<h5 id="3、写请求过程"><a href="#3、写请求过程" class="headerlink" title="3、写请求过程"></a>3、写请求过程</h5><ul>
<li><p>1、客户端上传文件时，NN首先往edits log文件中记录元数据操作日志，然后返回分配好的的三个足够存储的datanode信息空间告诉客户端。</p>
</li>
<li><p>2、客户端开始上传文件，完成后返回成功信息给NN，NN就在内存中写入这次上传操作的新产生的元数据信息</p>
</li>
<li><p>3、每当editslog写满时，需要将这一段时间的新的元数据刷新到fsimage文件中去（保证断电不丢失），edits log和fsimage进行合并，由SecondaryNameNode来解决</p>
</li>
</ul>
<h4 id="3-2、SecondaryNameNode合并机制"><a href="#3-2、SecondaryNameNode合并机制" class="headerlink" title="3.2、SecondaryNameNode合并机制"></a>3.2、SecondaryNameNode合并机制</h4><p><img src="http://img.mxranger.cn/Hadoop/1552804003343.png" alt="1552804003343"></p>
<h5 id="1、secondary-namenode的工作流程："><a href="#1、secondary-namenode的工作流程：" class="headerlink" title="1、secondary namenode的工作流程："></a>1、secondary namenode的工作流程：</h5><p>1、secondary通知namenode切换edits文件<br>2、secondary从namenode获得fsimage和edits(通过http)<br>3、secondary将fsimage载入内存，然后开始合并edits<br>4、secondary将新的fsimage发回给namenode<br>5、namenode用新的fsimage替换旧的fsimage</p>
<h5 id="2、何时checkpoint"><a href="#2、何时checkpoint" class="headerlink" title="2、何时checkpoint"></a>2、何时checkpoint</h5><p>1、fs.checkpoint.period 指定两次checkpoint的最大时间间隔，默认3600秒。 </p>
<p>2、fs.checkpoint.size    规定edits文件的最大值，一旦超过这个值则强制checkpoint，不管是否到达最大时间间隔。默认大小是64M。</p>
<h4 id="3-3、datanode工作原理"><a href="#3-3、datanode工作原理" class="headerlink" title="3.3、datanode工作原理"></a>3.3、datanode工作原理</h4><blockquote>
<p>提供真实文件数据的存储服务。</p>
<p>​    文件块（block）：<strong>最基本的存储单位</strong>。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB，以一个256MB文件，共有256/128=2个Block.<br>dfs.block.size<br>​    不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间<br>​    Replication。多复本。默认是三个。</p>
</blockquote>
<p>存放的切片在<code>/var/hadoop/dfs/data/current/BP-1550927103-192.168.159.200-1552638035901/current/finalized/subdir0/subdir0</code>中（tmp已经在配置文件中改过）</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552805695709.png" alt="1552805695709"></p>
<h2 id="2、使用JAVA进行HDFS编程"><a href="#2、使用JAVA进行HDFS编程" class="headerlink" title="2、使用JAVA进行HDFS编程"></a>2、使用JAVA进行HDFS编程</h2><h3 id="1、maven引包"><a href="#1、maven引包" class="headerlink" title="1、maven引包"></a>1、maven引包</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceencoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceencoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.8.5<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2、CRUD"><a href="#2、CRUD" class="headerlink" title="2、CRUD"></a>2、CRUD</h3><h4 id="1、读取文本"><a href="#1、读取文本" class="headerlink" title="1、读取文本"></a>1、读取文本</h4><p><strong>方法一：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">InputStream in = <span class="keyword">new</span> URL(<span class="string">&quot;hdfs://192.168.159.200:9000/content.txt&quot;</span>).openStream();</span><br><span class="line">IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>

<p><strong>方法二：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://192.168.159.200:9000&quot;</span>);</span><br><span class="line"><span class="comment">//conf.set(&quot;dfs.replication&quot;, &quot;5&quot;);</span></span><br><span class="line">FileSystem fileSystem = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    fileSystem = FileSystem.get(conf);</span><br><span class="line">    <span class="comment">//目录是否存在</span></span><br><span class="line">    <span class="keyword">boolean</span> b = fileSystem.exists(<span class="keyword">new</span> Path(<span class="string">&quot;/hello&quot;</span>));</span><br><span class="line">    System.out.println(b);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取文件</span></span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">&quot;/outcontent1/part-r-00000&quot;</span>));</span><br><span class="line">    <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4096</span>];</span><br><span class="line">    <span class="keyword">int</span> length;</span><br><span class="line">    <span class="keyword">while</span> ((length = in.read(buf))!= -<span class="number">1</span>)&#123;</span><br><span class="line">        System.out.println(<span class="keyword">new</span> String(buf,<span class="number">0</span>,length));</span><br><span class="line">    &#125;</span><br><span class="line">    in.close();</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以使用FileOutputStream保存文件</p>
<p>FileOutputStream out = new FileOutputStream(“f:/download.txt”);</p>
<p>IOUtils.copy(in,out);</p>
</blockquote>
<h4 id="2、创建目录"><a href="#2、创建目录" class="headerlink" title="2、创建目录"></a>2、创建目录</h4><p>创建目录,返回成功失败</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> success = fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">&quot;/mxranger&quot;</span>));</span><br><span class="line">System.out.println(success);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>报权限错误：</p>
<p>两种方法<br>                [1]如果报权限错误，设置dfs.permissions.enabled为false重启hadoop即可<br>                [2]修改文件的访问者,权限    System.setProperty(“HADOOP_USER_NAME”, “root”);</p>
</blockquote>
<h4 id="3、删除文件或目录"><a href="#3、删除文件或目录" class="headerlink" title="3、删除文件或目录"></a>3、删除文件或目录</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> success = fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">&quot;/content.txt&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">System.out.println(success);</span><br></pre></td></tr></table></figure>

<h4 id="4、上传文件"><a href="#4、上传文件" class="headerlink" title="4、上传文件"></a>4、上传文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//windows文件扔到hdfs上</span></span><br><span class="line"><span class="comment">//true  覆盖  false 追加</span></span><br><span class="line">FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">&quot;/content.txt&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="string">&quot;f:/content.txt&quot;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   无法查看进度</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">IOUtils.copyBytes(fis, out, <span class="number">4096</span>, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    等同于以下代码：可以显示进度</span></span><br><span class="line"><span class="comment">    byte[] buf = new byte[4096];</span></span><br><span class="line"><span class="comment">    int len = fis.read(buf);</span></span><br><span class="line"><span class="comment">    while(len!= -1)&#123;</span></span><br><span class="line"><span class="comment">    out.write(buf,0,len);</span></span><br><span class="line"><span class="comment">    len = fis.read(buf);</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    fis.close();</span></span><br><span class="line"><span class="comment">    out.close();</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="5、查看目录列表"><a href="#5、查看目录列表" class="headerlink" title="5、查看目录列表"></a>5、查看目录列表</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> FileStatus[] statuses = fileSystem.listStatus(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>));</span><br><span class="line"><span class="comment">//System.out.println(statuses.length);</span></span><br><span class="line"><span class="keyword">for</span>(FileStatus status : statuses) &#123;</span><br><span class="line">    System.out.print(status.getPath() + <span class="string">&quot; &quot;</span>);</span><br><span class="line">    System.out.print(status.getPermission() + <span class="string">&quot; &quot;</span>);</span><br><span class="line">    System.out.print(status.getReplication());</span><br><span class="line">    System.out.println();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3、RPC框架思想"><a href="#3、RPC框架思想" class="headerlink" title="3、RPC框架思想"></a>3、RPC框架思想</h2><blockquote>
<p>webservice    类似于dubbo</p>
</blockquote>
<p><img src="http://img.mxranger.cn/Hadoop/1552809815104.png" alt="1552809815104"></p>
<h3 id="应用："><a href="#应用：" class="headerlink" title="应用："></a>应用：</h3><p>服务端：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">LoginServiceInterface</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> versionID=<span class="number">1L</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">login</span><span class="params">(String username,String password)</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginServiceImpl</span> <span class="keyword">implements</span> <span class="title">LoginServiceInterface</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">login</span><span class="params">(String username, String password)</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> username + <span class="string">&quot; logged in successfully!&quot;</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Starter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> HadoopIllegalArgumentException, IOException </span>&#123;</span><br><span class="line">		</span><br><span class="line">		Builder builder = <span class="keyword">new</span> RPC.Builder(<span class="keyword">new</span> Configuration());</span><br><span class="line">		</span><br><span class="line">builder.setBindAddress(<span class="string">&quot;weekend110&quot;</span>).setPort(<span class="number">10000</span>).setProtocol(LoginServiceInterface.class).setInstance(<span class="keyword">new</span> LoginServiceImpl());</span><br><span class="line"></span><br><span class="line">		Server server = builder.build();</span><br><span class="line">		server.start();	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>客户端：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">LoginServiceInterface</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> versionID=<span class="number">1L</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">login</span><span class="params">(String username,String password)</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		LoginServiceInterface proxy = RPC.getProxy(LoginServiceInterface.class, <span class="number">1L</span>, <span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;weekend110&quot;</span>, <span class="number">10000</span>), <span class="keyword">new</span> Configuration());</span><br><span class="line">		</span><br><span class="line">		String result = proxy.login(<span class="string">&quot;mijie&quot;</span>, <span class="string">&quot;123456&quot;</span>);</span><br><span class="line">		</span><br><span class="line">		System.out.println(result);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>思考：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552810550411.png" alt="1552810550411"></p>
<h2 id="4、MapReduce"><a href="#4、MapReduce" class="headerlink" title="4、MapReduce"></a>4、MapReduce</h2><h3 id="1、WordCount工作过程"><a href="#1、WordCount工作过程" class="headerlink" title="1、WordCount工作过程"></a>1、WordCount工作过程</h3><p><img src="http://img.mxranger.cn/Hadoop/2019-03-15_223607.png" alt="2019-03-15_223607"></p>
<h3 id="2、分词统计"><a href="#2、分词统计" class="headerlink" title="2、分词统计"></a>2、分词统计</h3><h4 id="1、自定义Map和Reduce"><a href="#1、自定义Map和Reduce" class="headerlink" title="1、自定义Map和Reduce"></a>1、自定义Map和Reduce</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.mr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName WordMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/16</span></span><br><span class="line"><span class="comment"> * Time      10:26</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mapper&lt;LongWritable, Text, Text, IntWritable&gt;</span></span><br><span class="line"><span class="comment"> *     输入：key LongWritable  input拆分出来的每一行的起始位置</span></span><br><span class="line"><span class="comment"> *          value Text          每行内容</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *     输出：key Text 内容</span></span><br><span class="line"><span class="comment"> *          value 次数</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> IntWritable ONE = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        String line = value.toString(); <span class="comment">// hello java</span></span><br><span class="line">        String[] words = line.split(<span class="string">&quot; &quot;</span>);<span class="comment">// words = [&quot;hello&quot;,&quot;java&quot;]</span></span><br><span class="line">        <span class="keyword">for</span>(String word : words) &#123;</span><br><span class="line">            context.write(<span class="keyword">new</span> Text(word), ONE);<span class="comment">//往外写，扔给shuffle  单词,出现次数</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.mr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName WordReducer</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/16</span></span><br><span class="line"><span class="comment"> * Time      10:28</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *      输入：Text  包含value的list   比如:hello    list = [1,1,1,1,1,1]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="params"><span class="function">                          Reducer&lt;Text, IntWritable, Text, LongWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(IntWritable v : values) &#123;</span><br><span class="line">            count += v.get();</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> LongWritable(count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2、统计方式"><a href="#2、统计方式" class="headerlink" title="2、统计方式"></a>2、统计方式</h4><h5 id="【1】本地脱离hdfs独立运行MR"><a href="#【1】本地脱离hdfs独立运行MR" class="headerlink" title="【1】本地脱离hdfs独立运行MR"></a>【1】本地脱离hdfs独立运行MR</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.mr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName Test</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/16</span></span><br><span class="line"><span class="comment"> * Time      10:31</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 远程服务器执行  不指定远程的东西，默认是本地的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(WordMapper.class);</span><br><span class="line">        job.setReducerClass(WordReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">      	<span class="comment">//处理本地</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="string">&quot;f://content.txt&quot;</span>);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">&quot;f://outcontent&quot;</span>));</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="【2】拉取hdfs文件到本地运行，然后在保存到hdfs"><a href="#【2】拉取hdfs文件到本地运行，然后在保存到hdfs" class="headerlink" title="【2】拉取hdfs文件到本地运行，然后在保存到hdfs"></a>【2】拉取hdfs文件到本地运行，然后在保存到hdfs</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//服务器文件拉取到本地</span></span><br><span class="line"> FileInputFormat.setInputPaths(job, <span class="string">&quot;hdfs://master:9000/content.txt&quot;</span>);</span><br><span class="line"> FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">&quot;hdfs://master:9000/outcontent&quot;</span>));</span><br></pre></td></tr></table></figure>

<p><strong>注意这里是把hdfs文件拉到本地来运行，如果观察输出的话会观察到jobID带有local字样,同时这样的运行方式是不需要yarn的(自己停掉yarn服务做实验)</strong></p>
<h5 id="【3】远程使用MR"><a href="#【3】远程使用MR" class="headerlink" title="【3】远程使用MR"></a>【3】远程使用MR</h5><blockquote>
<p>​    也可以将hadoop的四个配置文件拿下来放到src根目录下，就不需要进行手工配置了，默认到classpath目录寻找</p>
<p>​    或者将配置文件放到别的地方，使用conf.addResource(.class.getClassLoader.getResourceAsStream)方式添加，不推荐使用绝对路径的方式</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.mr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName Test</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/16</span></span><br><span class="line"><span class="comment"> * Time      10:31</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 远程服务器执行  不指定远程的东西，默认是本地的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://master:9000/&quot;</span>);</span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">        <span class="comment">//将jar包扔上去</span></span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.job.jar&quot;</span>, <span class="string">&quot;target/HadoopProject-1.0-SNAPSHOT.jar&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.framework.name&quot;</span>, <span class="string">&quot;yarn&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;yarn.resourcemanager.hostname&quot;</span>, <span class="string">&quot;master&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.app-submission.cross-platform&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(WordMapper.class);</span><br><span class="line">        job.setReducerClass(WordReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="string">&quot;/content.txt&quot;</span>);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">&quot;/outcontent1&quot;</span>));</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3、使用Maven运行MR"><a href="#3、使用Maven运行MR" class="headerlink" title="3、使用Maven运行MR"></a>3、使用Maven运行MR</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>groupId<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HadoopProject<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceencoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceencoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.8.5<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置log4j.properties，放到src/main/resources目录下                 </p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">`log4j.rootCategory</span>=<span class="string">INFO, stdout` `log4j.appender.stdout=org.apache.log4j.ConsoleAppender   ``log4j.appender.stdout.layout=org.apache.log4j.PatternLayout   ``log4j.appender.stdout.layout.ConversionPattern=[QC] %p [%t] %C.%M(%L) | %m%n`</span></span><br></pre></td></tr></table></figure>



<h3 id="3、流量统计案例"><a href="#3、流量统计案例" class="headerlink" title="3、流量统计案例"></a>3、流量统计案例</h3><p>数据如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552819880197.png" alt="1552819880197"></p>
<h4 id="1、自定义Map和Reduce-1"><a href="#1、自定义Map和Reduce-1" class="headerlink" title="1、自定义Map和Reduce"></a>1、自定义Map和Reduce</h4><h5 id="1、传输对象FlowBean"><a href="#1、传输对象FlowBean" class="headerlink" title="1、传输对象FlowBean"></a>1、传输对象FlowBean</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName FlowBean</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/17</span></span><br><span class="line"><span class="comment"> * Time      16:29</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowBean</span> <span class="keyword">implements</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String phoneNumber;<span class="comment">//手机号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> up_flow;<span class="comment">//上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> down_flow;<span class="comment">//下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sum_flow;<span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//在反序列化时，反射机制需要调用空参构造函数，所以显示定义空参构造函数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FlowBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//为了对象数据的初始化方便</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FlowBean</span><span class="params">(String phoneNumber, <span class="keyword">long</span> up_flow, <span class="keyword">long</span> down_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.phoneNumber = phoneNumber;</span><br><span class="line">        <span class="keyword">this</span>.up_flow = up_flow;</span><br><span class="line">        <span class="keyword">this</span>.down_flow = down_flow;</span><br><span class="line">        <span class="keyword">this</span>.sum_flow = up_flow + down_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将对象数据序列化到流中</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        dataOutput.writeUTF(phoneNumber);</span><br><span class="line">        dataOutput.writeLong(up_flow);</span><br><span class="line">        dataOutput.writeLong(down_flow);</span><br><span class="line">        dataOutput.writeLong(sum_flow);</span><br><span class="line">        System.out.println(<span class="string">&quot;flowbean::&quot;</span>+phoneNumber+up_flow+down_flow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//从数据流中反序列出对象的数据，复原对象</span></span><br><span class="line">    <span class="comment">//从数据流中读出对象字段时，必须跟序列化时的顺序保持一致</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String phoneNumber = dataInput.readUTF();</span><br><span class="line">        up_flow = dataInput.readLong();</span><br><span class="line">        down_flow = dataInput.readLong();</span><br><span class="line">        sum_flow = dataInput.readLong();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span> + up_flow + <span class="string">&quot;\t&quot;</span> + down_flow + <span class="string">&quot;\t&quot;</span> + sum_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPhoneNumber</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> phoneNumber;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPhoneNumber</span><span class="params">(String phoneNumber)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.phoneNumber = phoneNumber;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getUp_flow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> up_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp_flow</span><span class="params">(<span class="keyword">long</span> up_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.up_flow = up_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getDown_flow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> down_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDown_flow</span><span class="params">(<span class="keyword">long</span> down_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.down_flow = down_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getSum_flow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sum_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSum_flow</span><span class="params">(<span class="keyword">long</span> sum_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sum_flow = sum_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="2、FlowSumMapper"><a href="#2、FlowSumMapper" class="headerlink" title="2、FlowSumMapper"></a>2、FlowSumMapper</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName FlowSumMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/17</span></span><br><span class="line"><span class="comment"> * Time      16:27</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  * FlowBean 是我们自定义的一种数据类型，倒在hadoop的各个节点之间传输，应该尊混hadoop的序列化机制</span></span><br><span class="line"><span class="comment"> *  * 就必须实现hadoop的序列化接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>,<span class="title">Text</span>,<span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 拿到日志中的一行数据，切分各个字段，抽取出我们需要的字段：手机号、上行流量、下行流量，然后封装key出去</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//哪一行数据</span></span><br><span class="line">        String line = value.toString();</span><br><span class="line">        <span class="comment">//切分出各个字段</span></span><br><span class="line">        String[] fields = StringUtils.split(line, <span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//拿到我们需要的字段</span></span><br><span class="line">        String phoneNumber = fields[<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">long</span> up_flow = Long.parseLong(fields[<span class="number">7</span>]);</span><br><span class="line">        <span class="keyword">long</span> down_flow = Long.parseLong(fields[<span class="number">8</span>]);</span><br><span class="line">        System.out.println(up_flow+<span class="string">&quot;::&quot;</span>+down_flow);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//封装数据kv输出</span></span><br><span class="line">        context.write(<span class="keyword">new</span> Text(phoneNumber),</span><br><span class="line">                <span class="keyword">new</span> FlowBean(phoneNumber,up_flow,down_flow));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="3、FlowSumReducer"><a href="#3、FlowSumReducer" class="headerlink" title="3、FlowSumReducer"></a>3、FlowSumReducer</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName FlowSumMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/17</span></span><br><span class="line"><span class="comment"> * Time      16:27</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">FlowBean</span>, <span class="title">Text</span>,<span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 框架没传递一组数据&lt;138xxxxxxxxxxx,&#123;flowbean,flowbean,flowbean,.....&#125;&gt;调用我们reduce方法</span></span><br><span class="line"><span class="comment">     * reduce中的业务逻辑就是遍历values，然后进行类加求和再输出</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> values</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> up_flow = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">long</span> down_flow = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (FlowBean flowBean : values)&#123;</span><br><span class="line">            up_flow += flowBean.getUp_flow();</span><br><span class="line">            down_flow += flowBean.getDown_flow();</span><br><span class="line">            System.out.println(<span class="string">&quot;up::&quot;</span>+flowBean.getUp_flow()+<span class="string">&quot;down::&quot;</span>+flowBean.getDown_flow());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//output出来的对象一定是tostring()方法，所以需要对FlowBean的toString进行修改，否则输出对象地址</span></span><br><span class="line">        context.write(key,<span class="keyword">new</span> FlowBean(key.toString(),up_flow,down_flow));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="4、FlowSumRunner远程执行方式"><a href="#4、FlowSumRunner远程执行方式" class="headerlink" title="4、FlowSumRunner远程执行方式"></a>4、FlowSumRunner远程执行方式</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cn.mxranger.mr.WordMapper;</span><br><span class="line"><span class="keyword">import</span> cn.mxranger.mr.WordReducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName FlowSumRunner</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/17</span></span><br><span class="line"><span class="comment"> * Time      16:28</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 这是job描述和提交类的规范写法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] strings)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//System.setProperty(&quot;HADOOP_USER_NAME&quot;,&quot;root&quot;);</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(FlowSumMapper.class);</span><br><span class="line">        job.setReducerClass(FlowSumReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="string">&quot;f://hadooptest//flow.dat&quot;</span>);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">&quot;f://hadooptest//out&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> :<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> result = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> FlowSumRunner(), args);</span><br><span class="line">            System.exit(result);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h5 id="5、FlowSumCmdRunner（命令方式）"><a href="#5、FlowSumCmdRunner（命令方式）" class="headerlink" title="5、FlowSumCmdRunner（命令方式）"></a>5、FlowSumCmdRunner（命令方式）</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName FlowSumRunner</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/17</span></span><br><span class="line"><span class="comment"> * Time      16:28</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 这是job描述和提交类的规范写法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumCmdRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] strings)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//System.setProperty(&quot;HADOOP_USER_NAME&quot;,&quot;root&quot;);</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(FlowSumCmdRunner.class);<span class="comment">//不加这行会有ClassNotFoundException</span></span><br><span class="line">        job.setMapperClass(FlowSumMapper.class);</span><br><span class="line">        job.setReducerClass(FlowSumReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job,  <span class="keyword">new</span> Path(strings[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(strings[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> :<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> result = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> FlowSumCmdRunner(), args);</span><br><span class="line">            System.exit(result);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="6、打包上传"><a href="#6、打包上传" class="headerlink" title="6、打包上传"></a>6、打包上传</h5><p>输入命令<code>hadoop jar HadoopProject-1.0-SNAPSHOT.jar cn.mxranger.flowsum.FlowSumCmdRunner /flowsum/data.dat /flowsum/out</code></p>
<p>结果如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552820090127.png" alt="1552820090127"></p>
<h4 id="2、流量排序（二次MR）"><a href="#2、流量排序（二次MR）" class="headerlink" title="2、流量排序（二次MR）"></a>2、流量排序（二次MR）</h4><blockquote>
<p>借助key的排序来实现</p>
</blockquote>
<h5 id="1、传输对象FlowBean-1"><a href="#1、传输对象FlowBean-1" class="headerlink" title="1、传输对象FlowBean"></a>1、传输对象FlowBean</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName FlowBean</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/17</span></span><br><span class="line"><span class="comment"> * Time      16:29</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowBean</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String phoneNumber;<span class="comment">//手机号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> up_flow;<span class="comment">//上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> down_flow;<span class="comment">//下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sum_flow;<span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//在反序列化时，反射机制需要调用空参构造函数，所以显示定义空参构造函数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FlowBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//为了对象数据的初始化方便</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FlowBean</span><span class="params">(String phoneNumber, <span class="keyword">long</span> up_flow, <span class="keyword">long</span> down_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.phoneNumber = phoneNumber;</span><br><span class="line">        <span class="keyword">this</span>.up_flow = up_flow;</span><br><span class="line">        <span class="keyword">this</span>.down_flow = down_flow;</span><br><span class="line">        <span class="keyword">this</span>.sum_flow = up_flow + down_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将对象数据序列化到流中</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        dataOutput.writeUTF(phoneNumber);</span><br><span class="line">        dataOutput.writeLong(up_flow);</span><br><span class="line">        dataOutput.writeLong(down_flow);</span><br><span class="line">        dataOutput.writeLong(sum_flow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//从数据流中反序列出对象的数据，复原对象</span></span><br><span class="line">    <span class="comment">//从数据流中读出对象字段时，必须跟序列化时的顺序保持一致</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        phoneNumber = dataInput.readUTF();</span><br><span class="line">        up_flow = dataInput.readLong();</span><br><span class="line">        down_flow = dataInput.readLong();</span><br><span class="line">        sum_flow = dataInput.readLong();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span> + up_flow + <span class="string">&quot;\t&quot;</span> + down_flow + <span class="string">&quot;\t&quot;</span> + sum_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPhoneNumber</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> phoneNumber;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPhoneNumber</span><span class="params">(String phoneNumber)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.phoneNumber = phoneNumber;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getUp_flow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> up_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp_flow</span><span class="params">(<span class="keyword">long</span> up_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.up_flow = up_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getDown_flow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> down_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDown_flow</span><span class="params">(<span class="keyword">long</span> down_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.down_flow = down_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getSum_flow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sum_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSum_flow</span><span class="params">(<span class="keyword">long</span> sum_flow)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sum_flow = sum_flow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/*</span></span><br><span class="line"><span class="comment">   key排序比较</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(FlowBean o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sum_flow &gt; o.getSum_flow() ? -<span class="number">1</span>: <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="2、SortCMDMR"><a href="#2、SortCMDMR" class="headerlink" title="2、SortCMDMR"></a>2、SortCMDMR</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowsort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SortCMDMR</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SortMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">FlowBean</span>, <span class="title">NullWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">//拿到一行数据，切分出各字段，封装为一个flowbean，作为key输出</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value,Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">			String line = value.toString();</span><br><span class="line">			</span><br><span class="line">			String[] fields = StringUtils.split(line, <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">			</span><br><span class="line">			String phoneNB = fields[<span class="number">0</span>];</span><br><span class="line">			<span class="keyword">long</span> u_flow = Long.parseLong(fields[<span class="number">1</span>]);</span><br><span class="line">			<span class="keyword">long</span> d_flow = Long.parseLong(fields[<span class="number">2</span>]);</span><br><span class="line">			System.out.println(phoneNB+<span class="string">&quot;::&quot;</span>+u_flow+<span class="string">&quot;::&quot;</span>+d_flow);</span><br><span class="line">			</span><br><span class="line">			context.write(<span class="keyword">new</span> FlowBean(phoneNB, u_flow, d_flow), NullWritable.get());</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SortReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">FlowBean</span>, <span class="title">NullWritable</span>, <span class="title">Text</span>, <span class="title">FlowBean</span>&gt;</span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(FlowBean key, Iterable&lt;NullWritable&gt; values,Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			System.out.println(key.toString());</span><br><span class="line">			String phoneNB = key.getPhoneNumber();</span><br><span class="line">			System.out.println(<span class="string">&quot;key::&quot;</span>+phoneNB);</span><br><span class="line">			context.write(<span class="keyword">new</span> Text(phoneNB), key);</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();	</span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		job.setJarByClass(SortCMDMR.class);</span><br><span class="line">		</span><br><span class="line">		job.setMapperClass(SortMapper.class);</span><br><span class="line">		job.setReducerClass(SortReducer.class);</span><br><span class="line">		</span><br><span class="line">		job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">		job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line">		</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(FlowBean.class);</span><br><span class="line">		</span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">		System.exit(job.waitForCompletion(<span class="keyword">true</span>)?<span class="number">0</span>:<span class="number">1</span>);	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="3、打包上传"><a href="#3、打包上传" class="headerlink" title="3、打包上传"></a>3、打包上传</h5><p>命令<code>hadoop jar HadoopProject-1.0-SNAPSHOT.jar cn.mxranger.flowsort.SortCMDMR /flowsum/out/part-r-00000 /flowsum/flowsort/out</code></p>
<p>结果如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552820257572.png" alt="1552820257572"></p>
<h4 id="3、自定义分组"><a href="#3、自定义分组" class="headerlink" title="3、自定义分组"></a>3、自定义分组</h4><blockquote>
<p>对流量原始日志进行流量统计，将不同省份的用户统计结果输出到不同文件</p>
<p>需要自定义改造两个机制：</p>
<ul>
<li>1、改造分区的逻辑，自定义一个partitioner</li>
<li>2、自定义reduer task的并发任务数</li>
</ul>
</blockquote>
<h5 id="1、AreaPartitioner"><a href="#1、AreaPartitioner" class="headerlink" title="1、AreaPartitioner"></a>1、AreaPartitioner</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.mr.areapartition;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AreaPartitioner</span>&lt;<span class="title">KEY</span>, <span class="title">VALUE</span>&gt; <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">KEY</span>, <span class="title">VALUE</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> HashMap&lt;String,Integer&gt; areaMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">static</span>&#123;</span><br><span class="line">		areaMap.put(<span class="string">&quot;135&quot;</span>, <span class="number">0</span>);</span><br><span class="line">		areaMap.put(<span class="string">&quot;136&quot;</span>, <span class="number">1</span>);</span><br><span class="line">		areaMap.put(<span class="string">&quot;137&quot;</span>, <span class="number">2</span>);</span><br><span class="line">		areaMap.put(<span class="string">&quot;138&quot;</span>, <span class="number">3</span>);</span><br><span class="line">		areaMap.put(<span class="string">&quot;139&quot;</span>, <span class="number">4</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(KEY key, VALUE value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">		<span class="comment">//从key中拿到手机号，查询手机归属地字典，不同的省份返回不同的组号</span></span><br><span class="line">		</span><br><span class="line">		<span class="keyword">int</span> areaCoder  = areaMap.get(key.toString().substring(<span class="number">0</span>, <span class="number">3</span>))==<span class="keyword">null</span>?<span class="number">5</span>:areaMap.get(key.toString().substring(<span class="number">0</span>, <span class="number">3</span>));</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> areaCoder;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="2、自定义MR"><a href="#2、自定义MR" class="headerlink" title="2、自定义MR"></a>2、自定义MR</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.mr.areapartition;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cn.itcast.hadoop.mr.flowsum.FlowBean;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对流量原始日志进行流量统计，将不同省份的用户统计结果输出到不同文件</span></span><br><span class="line"><span class="comment"> * 需要自定义改造两个机制：</span></span><br><span class="line"><span class="comment"> * 1、改造分区的逻辑，自定义一个partitioner</span></span><br><span class="line"><span class="comment"> * 2、自定义reduer task的并发任务数</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> duanhaitao@itcast.cn</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumArea</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumAreaMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">FlowBean</span>&gt;</span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value,Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">//拿一行数据</span></span><br><span class="line">			String line = value.toString();</span><br><span class="line">			<span class="comment">//切分成各个字段</span></span><br><span class="line">			String[] fields = StringUtils.split(line, <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">//拿到我们需要的字段</span></span><br><span class="line">			String phoneNB = fields[<span class="number">1</span>];</span><br><span class="line">			<span class="keyword">long</span> u_flow = Long.parseLong(fields[<span class="number">7</span>]);</span><br><span class="line">			<span class="keyword">long</span> d_flow = Long.parseLong(fields[<span class="number">8</span>]);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">//封装数据为kv并输出</span></span><br><span class="line">			context.write(<span class="keyword">new</span> Text(phoneNB), <span class="keyword">new</span> FlowBean(phoneNB,u_flow,d_flow));</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowSumAreaReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">FlowBean</span>, <span class="title">Text</span>, <span class="title">FlowBean</span>&gt;</span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values,Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">long</span> up_flow_counter = <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">long</span> d_flow_counter = <span class="number">0</span>;</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">for</span>(FlowBean bean: values)&#123;</span><br><span class="line">				</span><br><span class="line">				up_flow_counter += bean.getUp_flow();</span><br><span class="line">				d_flow_counter += bean.getD_flow();</span><br><span class="line">				</span><br><span class="line">				</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">			context.write(key, <span class="keyword">new</span> FlowBean(key.toString(), up_flow_counter, d_flow_counter));</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		job.setJarByClass(FlowSumArea.class);</span><br><span class="line">		</span><br><span class="line">		job.setMapperClass(FlowSumAreaMapper.class);</span><br><span class="line">		job.setReducerClass(FlowSumAreaReducer.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//设置我们自定义的分组逻辑定义</span></span><br><span class="line">		job.setPartitionerClass(AreaPartitioner.class);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(FlowBean.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//设置reduce的任务并发数，应该跟分组的数量保持一致</span></span><br><span class="line">		job.setNumReduceTasks(<span class="number">6</span>);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		System.exit(job.waitForCompletion(<span class="keyword">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552821031140.png" alt="1552821031140"></p>
<h1 id="二、Zookeeper"><a href="#二、Zookeeper" class="headerlink" title="二、Zookeeper"></a>二、Zookeeper</h1><h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><blockquote>
<p>​    Zookeeper 是 Google 的 Chubby一个开源的实现，是 Hadoop 的分布式协调服务，同步数据</p>
</blockquote>
<p><img src="http://img.mxranger.cn/Hadoop/1552877310300.png" alt="1552877310300"></p>
<h3 id="1、节点"><a href="#1、节点" class="headerlink" title="1、节点"></a>1、节点</h3><p>Znode有两种类型，短暂的（ephemeral）和持久的（persistent）<br>Znode的类型在创建时确定并且之后不能再修改<br>短暂znode的客户端会话结束时，zookeeper会将该短暂znode删除，短暂znode不可以有子节点<br>持久znode不依赖于客户端会话，只有当客户端明确要删除该持久znode时才会被删除<br>Znode有四种形式的目录节点，PERSISTENT、PERSISTENT_SEQUENTIAL、EPHEMERAL、EPHEMERAL_SEQUENTIAL</p>
<h2 id="2、总结"><a href="#2、总结" class="headerlink" title="2、总结"></a>2、总结</h2><p>​    Zookeeper 作为 Hadoop 项目中的一个子项目，是 Hadoop 集群管理的一个必不可少的模块，它主要用来控制集群中的数据，如它管理 Hadoop 集群中的 NameNode，还有 Hbase 中 Master Election、Server 之间状态同步等。<br>​    Zoopkeeper 提供了一套很好的分布式集群管理的机制，就是它这种基于层次型的目录树的数据结构，并对树中的节点进行有效管理，从而可以设计出多种多样的分布式的数据管理模型</p>
<h1 id="三、HA"><a href="#三、HA" class="headerlink" title="三、HA"></a>三、HA</h1><h1 id="四、Hive"><a href="#四、Hive" class="headerlink" title="四、Hive"></a>四、Hive</h1><h2 id="1、介绍-1"><a href="#1、介绍-1" class="headerlink" title="1、介绍"></a>1、介绍</h2><blockquote>
<pre><code>    ​    **Hive是SQL解析引擎，它将SQL语句转译成M/R Job然后在Hadoop执行。**
</code></pre>
<p>​    Hive 是建立在 Hadoop  上的数据仓库基础构架。它提供了一系列的工具,封装了MapReduce的方法。<br>​    Hive的表其实就是HDFS的目录/文件，按表名把文件夹分开。如果是分区表，则分区值是子文件夹，可以直接在M/R Job里使用这些数据。</p>
</blockquote>
<p><img src="http://img.mxranger.cn/Hadoop/1552892725891.png" alt="1552892725891"></p>
<h2 id="2、安装"><a href="#2、安装" class="headerlink" title="2、安装"></a>2、安装</h2><p>【1】解压Hive，到/usr/local目录，将解压后的目录名mv为hive<br>【2】设定环境变量HADOOP_HOME，HIVE_HOME，将bin目录加入到PATH中</p>
<pre><code>cd /usr/local/hive/conf
cp hive-default.xml.template hive-site.xml

关闭版本验证
修改hive.metastore.schema.verification，设定为false
创建/usr/local/hive/tmp目录，替换$&#123;system:java.io.tmpdir&#125;为该目录
替换$&#123;system:user.name&#125;为root
</code></pre>
<p>【3】schematool -initSchema -dbType derby会在当前目录下简历metastore_db的数据库。注意！！！下次执行hive时应该还在同一目录，默认到当前目录下寻找metastore。遇到问题，把metastore_db删掉，重新执行命令<br><strong>实际工作环境中，经常使用mysql作为metastore的数据</strong><br>【4】启动hive</p>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><pre><code>观察hadoop fs -ls /tmp/hive中目录的创建
show databases;
use default;
create table doc(line string);
show tables;
desc doc;
select * from doc;
drop table doc;
</code></pre>
<h3 id="使用MySQL做Hive的元数据"><a href="#使用MySQL做Hive的元数据" class="headerlink" title="使用MySQL做Hive的元数据"></a>使用MySQL做Hive的元数据</h3><blockquote>
<p>修改hive-site.xml文件</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://192.168.159.100:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1234<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h3><h4 id="【1】执行sql语句报错SemanticException-org-apache-hadoop-hive-ql-metadata-HiveException"><a href="#【1】执行sql语句报错SemanticException-org-apache-hadoop-hive-ql-metadata-HiveException" class="headerlink" title="【1】执行sql语句报错SemanticException org.apache.hadoop.hive.ql.metadata.HiveException"></a>【1】执行sql语句报错SemanticException org.apache.hadoop.hive.ql.metadata.HiveException</h4><p>解决方案：</p>
<p>在hive的配置文件hive-site.xml添加如下配置：</p>
<pre><code> &lt;property&gt;
    &lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
</code></pre>
<p>然后删除MySQL中原来的表，重新初始化元数据</p>
<h4 id="【2】创建表报错Column-length-too-big-for-column-‘PARAM-VALUE’-max-21845-use-BLOB-or-Text-instead"><a href="#【2】创建表报错Column-length-too-big-for-column-‘PARAM-VALUE’-max-21845-use-BLOB-or-Text-instead" class="headerlink" title="【2】创建表报错Column length too big for column ‘PARAM_VALUE’(max=21845); use BLOB or Text instead"></a>【2】创建表报错Column length too big for column ‘PARAM_VALUE’(max=21845); use BLOB or Text instead</h4><p>解决方案：</p>
<p>删除hive自动生成的hive数据库，自建hive数据库，并设置编码集为 ：latin1，重新启动hive即可。</p>
<h3 id="mysql存储的元数据"><a href="#mysql存储的元数据" class="headerlink" title="mysql存储的元数据"></a>mysql存储的元数据</h3><p><img src="http://img.mxranger.cn/Hadoop/1552896781317.png" alt="1552896781317"></p>
<p>创建的表名在TBLS中</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552896853971.png" alt="1552896853971"></p>
<p>字段在COLUMNS_V2中</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552896868626.png" alt="1552896868626"></p>
<p>hive的database（默认库）</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552896921073.png" alt="1552896921073"></p>
<h2 id="3、hive使用"><a href="#3、hive使用" class="headerlink" title="3、hive使用"></a>3、hive使用</h2><h3 id="1、自制文本"><a href="#1、自制文本" class="headerlink" title="1、自制文本"></a>1、自制文本</h3><p><img src="http://img.mxranger.cn/Hadoop/1552899808395.png" alt="1552899808395"></p>
<h3 id="2、hive创建数据库test，创建表phone，导入文本内容"><a href="#2、hive创建数据库test，创建表phone，导入文本内容" class="headerlink" title="2、hive创建数据库test，创建表phone，导入文本内容"></a>2、hive创建数据库test，创建表phone，导入文本内容</h3><p><img src="http://img.mxranger.cn/Hadoop/1552899887229.png" alt="1552899887229"></p>
<p>元数据中保存了相关信息</p>
<p><img src="http://img.mxranger.cn/Hadoop/1552900352802.png" alt="1552900352802"></p>
<p><img src="http://img.mxranger.cn/Hadoop/1552899918178.png" alt="1552899918178"><br>内容保存到hdfs中<br><img src="http://img.mxranger.cn/Hadoop/1552900075355.png" alt="1552900075355"></p>
<p><img src="http://img.mxranger.cn/Hadoop/1552899866705.png" alt="1552899866705"></p>
<h3 id="3、计算总数"><a href="#3、计算总数" class="headerlink" title="3、计算总数"></a>3、计算总数</h3><p><img src="http://img.mxranger.cn/Hadoop/1552900035540.png" alt="1552900035540"></p>
<h1 id="五、HBase"><a href="#五、HBase" class="headerlink" title="五、HBase"></a>五、HBase</h1><h2 id="1、介绍-2"><a href="#1、介绍-2" class="headerlink" title="1、介绍"></a>1、介绍</h2><blockquote>
<p>Hbase ： Hadoop database，hadoop的数据库</p>
<p>NoSQL型数据库，按照列存储。HBASE是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统<img src="http://img.mxranger.cn/Hadoop/20170829103700692.png" alt="img"></p>
</blockquote>
<h3 id="HBase表结构"><a href="#HBase表结构" class="headerlink" title="HBase表结构"></a>HBase表结构</h3><p><img src="http://img.mxranger.cn/Hadoop/1552959574579.png" alt="1552959574579"></p>
<p>当表非常大的时候，会被切分成很多的Region，然后分别存储到不同的RegionServer上</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553003300369.png" alt="1553003300369"><br>Region Server通常和Datanode在一起<br><img src="http://img.mxranger.cn/Hadoop/1553003353007.png" alt="1553003353007"></p>
<h2 id="2、安装-1"><a href="#2、安装-1" class="headerlink" title="2、安装"></a>2、安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">1.上传hbase安装包</span><br><span class="line"></span><br><span class="line">2.解压</span><br><span class="line"></span><br><span class="line">3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）</span><br><span class="line">	注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下</span><br><span class="line">	</span><br><span class="line">	3.1修改hbase-env.sh</span><br><span class="line">	export JAVA_HOME=/usr/java/jdk1.7.0_55</span><br><span class="line">	//告诉hbase使用外部的zk</span><br><span class="line">	export HBASE_MANAGES_ZK=false</span><br><span class="line">	</span><br><span class="line">	vim hbase-site.xml</span><br><span class="line">	&lt;configuration&gt;</span><br><span class="line">		&lt;!-- 指定hbase在HDFS上存储的路径 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">		&lt;!-- 指定hbase是分布式的 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">		&lt;!-- 指定zk的地址，多个用“,”分割 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;!--一定要配端口，否则web打不开--&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.master.info.port&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;60010&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">	&lt;/configuration&gt;</span><br><span class="line">	</span><br><span class="line">	vim regionservers</span><br><span class="line">	master</span><br><span class="line">	slave1</span><br><span class="line">	slave2</span><br><span class="line">	</span><br><span class="line">	3.2拷贝hbase到其他节点</span><br><span class="line">		scp -r /weekend/hbase-0.96.2-hadoop2/ slave1:/weekend/</span><br><span class="line">		scp -r /weekend/hbase-0.96.2-hadoop2/ slave2:/weekend/</span><br><span class="line"></span><br><span class="line">4.将配置好的HBase拷贝到每一个节点并同步时间。</span><br><span class="line"></span><br><span class="line">5.启动所有的hbase</span><br><span class="line">	分别启动zk</span><br><span class="line">		./zkServer.sh start</span><br><span class="line">	启动hbase集群</span><br><span class="line">		start-dfs.sh</span><br><span class="line">	启动hbase，在主节点上运行：</span><br><span class="line">		start-hbase.sh</span><br><span class="line">6.通过浏览器访问hbase管理页面</span><br><span class="line">	192.168.1.201:60010</span><br><span class="line">7.为保证集群的可靠性，要启动多个HMaster</span><br><span class="line">	hbase-daemon.sh start master</span><br><span class="line">	</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="http://img.mxranger.cn/Hadoop/1555643292655.png" alt="1555643292655"></p>
<h1 id="六、Storm"><a href="#六、Storm" class="headerlink" title="六、Storm"></a>六、Storm</h1><blockquote>
<p>分布式计算框架</p>
<p>​    MapReduce：主要做离线批量计算，数据挖掘、数据分析、数据统计</p>
<p>​    Storm：实时运算，流动的数据实时计算 </p>
<p>Storm有许多用例：实时分析，在线机器学习，连续计算，分布式RPC、ETL</p>
</blockquote>
<p><strong>Strom一般和消息队列、数据库搭配，消息队列是数据的源头，storm做实时处理，数据库作为数据的存储地</strong></p>
<h2 id="1、介绍-3"><a href="#1、介绍-3" class="headerlink" title="1、介绍"></a>1、介绍</h2><blockquote>
<p>​    Storm是一个开源的分布式实时计算系统，可以简单、可靠的处理大量的数据流。被称作“实时的hadoop”。</p>
<p><strong>Storm的基本概念：</strong></p>
<p>在深入理解Storm之前，需要了解一些概念：</p>
<p>Topologies ： 拓扑，也俗称一个任务</p>
<p>Spouts ： 拓扑的消息源</p>
<p>Bolts ： 拓扑的处理逻辑单元</p>
<p>tuple：消息元组</p>
<p>Streams ： 流</p>
<p>Stream groupings ：流的分组策略</p>
<p>Tasks ： 任务处理单元</p>
<p>Executor :工作线程</p>
<p>Workers ：工作进程</p>
<p>Configuration ： topology的配置</p>
</blockquote>
<p><img src="http://img.mxranger.cn/Hadoop/1553004912523.png" alt="1553004912523"></p>
<p><img src="http://img.mxranger.cn/Hadoop/1553062122787.png" alt="1553062122787"></p>
<p>storm集群的物理结构：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553065451448.png" alt="1553065451448"></p>
<h2 id="2、安装-2"><a href="#2、安装-2" class="headerlink" title="2、安装"></a>2、安装</h2><h3 id="1、zookeeper集群安装"><a href="#1、zookeeper集群安装" class="headerlink" title="1、zookeeper集群安装"></a>1、zookeeper集群安装</h3><p>1、zookeeper的默认配置文件为zookeeper/conf/zoo_sample.cfg，需要将其修改为zoo.cfg。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">1.tickTime：CS通信心跳时间</span><br><span class="line">Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。</span><br><span class="line">tickTime=2000  </span><br><span class="line"></span><br><span class="line">2.initLimit：LF初始通信时限</span><br><span class="line">集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。</span><br><span class="line">initLimit=5  </span><br><span class="line"></span><br><span class="line">3.syncLimit：LF同步通信时限</span><br><span class="line">集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。</span><br><span class="line">syncLimit=2  </span><br><span class="line"> </span><br><span class="line">4.dataDir：数据文件目录</span><br><span class="line">Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。</span><br><span class="line">dataDir=/home/michael/opt/zookeeper/data  </span><br><span class="line"></span><br><span class="line">5.clientPort：客户端连接端口</span><br><span class="line">客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。</span><br><span class="line">clientPort=2181 </span><br><span class="line"></span><br><span class="line">6.服务器名称与地址：集群信息（服务器编号，服务器地址，LF通信端口，选举端口）</span><br><span class="line">这个配置项的书写格式比较特殊，规则如下：</span><br><span class="line">server.N=YYY:A:B </span><br></pre></td></tr></table></figure>

<p>配置如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553065237906.png" alt="1553065237906"></p>
<p>2、启动</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">每个zookeeper节点的bin目录下</span><br><span class="line">./zkServer.sh start</span><br><span class="line"></span><br><span class="line">查看状态</span><br><span class="line">./zkServer.sh status</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2、storm集群搭建"><a href="#2、storm集群搭建" class="headerlink" title="2、storm集群搭建"></a>2、storm集群搭建</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1、上传storm的安装包，解压</span><br><span class="line"></span><br><span class="line">2、修改配置文件storm.yaml</span><br><span class="line"></span><br><span class="line">#所使用的zookeeper集群主机</span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line">     - &quot;weekend05&quot;</span><br><span class="line">     - &quot;weekend06&quot;</span><br><span class="line">     - &quot;weekend07&quot;</span><br><span class="line"></span><br><span class="line">#nimbus所在的主机名</span><br><span class="line">nimbus.host: &quot;weekend05&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">启动storm</span><br><span class="line">在nimbus主机上</span><br><span class="line">nohup ./storm nimbus 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">web查看  192.168.159.200:8080/</span><br><span class="line">nohup ./storm ui 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">在supervisor主机上</span><br><span class="line">nohup ./storm supervisor 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p><img src="http://img.mxranger.cn/Hadoop/1553068528248.png" alt="1553068528248"></p>
<h2 id="3、使用"><a href="#3、使用" class="headerlink" title="3、使用"></a>3、使用</h2><p>简单案例：</p>
<p>给单词转大小、加后缀</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553066263514.png" alt="1553066263514"></p>
<h3 id="1、水龙头Spout（流入口）"><a href="#1、水龙头Spout（流入口）" class="headerlink" title="1、水龙头Spout（流入口）"></a>1、水龙头Spout（流入口）</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.storm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName RandomWordSpout</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/20</span></span><br><span class="line"><span class="comment"> * Time      15:12</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RandomWordSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//模拟一些数据</span></span><br><span class="line">    String[] words = &#123;<span class="string">&quot;iphone&quot;</span>,<span class="string">&quot;xiaomi&quot;</span>,<span class="string">&quot;mate&quot;</span>,<span class="string">&quot;sony&quot;</span>,<span class="string">&quot;sumsung&quot;</span>,<span class="string">&quot;moto&quot;</span>,<span class="string">&quot;meizu&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//不断地往下一个组件发送tuple消息</span></span><br><span class="line">    <span class="comment">//这里面是该spout组件的核心逻辑</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//可以从kafka消息队列中拿到数据,简便起见，我们从words数组中随机挑选一个商品名发送出去</span></span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> index = random.nextInt(words.length);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过随机数拿到一个商品名</span></span><br><span class="line">        String godName = words[index];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//将商品名封装成tuple，发送消息给下一个组件</span></span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(godName));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//每发送一个消息，休眠500ms</span></span><br><span class="line">        Utils.sleep(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//初始化方法，在spout组件实例化时调用一次</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext context, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.collector = collector;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//声明本spout组件发送出去的tuple中的数据的字段名</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">&quot;orignname&quot;</span>));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2、处理blot"><a href="#2、处理blot" class="headerlink" title="2、处理blot"></a>2、处理blot</h3><h4 id="1、UpperBolt转成大写"><a href="#1、UpperBolt转成大写" class="headerlink" title="1、UpperBolt转成大写"></a>1、UpperBolt转成大写</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.storm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.BasicOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseBasicBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName UpperBolt</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/20</span></span><br><span class="line"><span class="comment"> * Time      15:12</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UpperBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//业务处理逻辑</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector collector)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//先获取到上一个组件传递过来的数据,数据在tuple里面</span></span><br><span class="line">        String godName = tuple.getString(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将商品名转换成大写</span></span><br><span class="line">        String godName_upper = godName.toUpperCase();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将转换完成的商品名发送出去</span></span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(godName_upper));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//声明该bolt组件要发出去的tuple的字段</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">&quot;uppername&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2、SuffixBolt-加后缀"><a href="#2、SuffixBolt-加后缀" class="headerlink" title="2、SuffixBolt 加后缀"></a>2、SuffixBolt 加后缀</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.storm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.BasicOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseBasicBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.FileWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName SuffixBolt</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/20</span></span><br><span class="line"><span class="comment"> * Time      15:12</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SuffixBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    FileWriter fileWriter = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在bolt组件运行过程中只会被调用一次</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map stormConf, TopologyContext context)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fileWriter = <span class="keyword">new</span> FileWriter(<span class="string">&quot;/root/storm/&quot;</span>+ UUID.randomUUID());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//该bolt组件的核心处理逻辑</span></span><br><span class="line">    <span class="comment">//每收到一个tuple消息，就会被调用一次</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector collector)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//先拿到上一个组件发送过来的商品名称</span></span><br><span class="line">        String upper_name = tuple.getString(<span class="number">0</span>);</span><br><span class="line">        String suffix_name = upper_name + <span class="string">&quot;_itisok&quot;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//为上一个组件发送过来的商品名称添加后缀</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fileWriter.write(suffix_name);</span><br><span class="line">            fileWriter.write(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">            fileWriter.flush();</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//本bolt已经不需要发送tuple消息到下一个组件，所以不需要再声明tuple的字段</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer arg0)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3、主函数"><a href="#3、主函数" class="headerlink" title="3、主函数"></a>3、主函数</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.storm;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName TopoMain</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/20</span></span><br><span class="line"><span class="comment"> * Time      15:12</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.StormTopology;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 组织各个处理组件形成一个完整的处理流程，就是所谓的topology(类似于mapreduce程序中的job)</span></span><br><span class="line"><span class="comment"> * 并且将该topology提交给storm集群去运行，topology提交到集群后就将永无休止地运行，除非人为或者异常退出</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> duanhaitao@itcast.cn</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TopoMain</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将我们的spout组件设置到topology中去</span></span><br><span class="line">        <span class="comment">//parallelism_hint ：4  表示用4个excutor来执行这个组件</span></span><br><span class="line">        <span class="comment">//setNumTasks(8) 设置的是该组件执行时的并发task数量，也就意味着1个excutor会运行2个task</span></span><br><span class="line">        builder.setSpout(<span class="string">&quot;randomspout&quot;</span>, <span class="keyword">new</span> RandomWordSpout(), <span class="number">4</span>).setNumTasks(<span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将大写转换bolt组件设置到topology，并且指定它接收randomspout组件的消息</span></span><br><span class="line">        <span class="comment">//.shuffleGrouping(&quot;randomspout&quot;)包含两层含义：</span></span><br><span class="line">        <span class="comment">//1、upperbolt组件接收的tuple消息一定来自于randomspout组件</span></span><br><span class="line">        <span class="comment">//2、randomspout组件和upperbolt组件的大量并发task实例之间收发消息时采用的分组策略是随机分组shuffleGrouping</span></span><br><span class="line">        builder.setBolt(<span class="string">&quot;upperbolt&quot;</span>, <span class="keyword">new</span> UpperBolt(), <span class="number">4</span>).shuffleGrouping(<span class="string">&quot;randomspout&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将添加后缀的bolt组件设置到topology，并且指定它接收upperbolt组件的消息</span></span><br><span class="line">        builder.setBolt(<span class="string">&quot;suffixbolt&quot;</span>, <span class="keyword">new</span> SuffixBolt(), <span class="number">4</span>).shuffleGrouping(<span class="string">&quot;upperbolt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//用builder来创建一个topology</span></span><br><span class="line">        StormTopology demotop = builder.createTopology();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//配置一些topology在集群中运行时的参数</span></span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        <span class="comment">//这里设置的是整个demotop所占用的槽位数，也就是worker的数量</span></span><br><span class="line">        conf.setNumWorkers(<span class="number">4</span>);</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line">        conf.setNumAckers(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//将这个topology提交给storm集群运行</span></span><br><span class="line">        StormSubmitter.submitTopology(<span class="string">&quot;demotopo&quot;</span>, conf, demotop);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4、打包jar"><a href="#4、打包jar" class="headerlink" title="4、打包jar"></a>4、打包jar</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">扔到服务器上，运行命令</span><br><span class="line">./storm jar ~/storm/HadoopProject-1.0-SNAPSHOT.jar cn.mxranger.storm.TopoMain</span><br></pre></td></tr></table></figure>

<p>保存目录下生成文件，<strong>永不停止</strong>实时处理数据</p>
<p><img src="http://img.mxranger.cn/Hadoop/storm.gif" alt="storm"></p>
<p> 当某一个worker关闭之后，其余的worker还会继续执行，相互不影响。重新启动supervisor即可运行worker<code>./storm supervisor</code></p>
<h2 id="4、Storm与Hadoop的对比"><a href="#4、Storm与Hadoop的对比" class="headerlink" title="4、Storm与Hadoop的对比"></a>4、Storm与Hadoop的对比</h2><p><strong>Topology 与 Mapreduce</strong><br>一个关键的区别是： 一个MapReduce job最终会结束， 而一个topology永远会运行（除非你手动kill掉）</p>
<p><strong>Nimbus 与 ResourManager</strong><br>在Storm的集群里面有两种节点： 控制节点（master node）和工作节点（worker node）。控制节点上面运行一个叫Nimbus后台程序，它的作用类似Hadoop里面的JobTracker。Nimbus负责在集群里面分发代码，分配计算任务给机器， 并且监控状态。</p>
<p><strong>Supervisor (worker进程)与NodeManager(YarnChild)</strong><br>每一个工作节点上面运行一个叫做Supervisor的节点。Supervisor会监听分配给它那台机器的工作，根据需要启动/关闭工作进程。每一个工作进程执行一个topology的一个子集；一个运行的topology由运行在很多机器上的很多工作进程组成。 </p>
<h2 id="5、Storm体系结构"><a href="#5、Storm体系结构" class="headerlink" title="5、Storm体系结构"></a>5、Storm体系结构</h2><p>【1】<strong>Storm中的Nimbus和Supervisor</strong></p>
<p>​    Nimbus和Supervisor之间的所有协调工作都是通过Zookeeper集群完成。</p>
<p>​    Nimbus进程和Supervisor进程都是快速失败（fail-fast)和无状态的。所有的状态要么在zookeeper里面， 要么在本地磁盘上。</p>
<p>​    这也就意味着你可以用kill -9来杀死Nimbus和Supervisor进程， 然后再重启它们，就好像什么都没有发生过。这个设计使得Storm异常的稳定。</p>
<p>Nimbus和Supervisor通过zookeeper来进行协调工作</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553085423373.png" alt="1553085423373"></p>
<h2 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h2><p><img src="http://img.mxranger.cn/Hadoop/1553086651668.png" alt="1553086651668"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">conf.setNumWorkers(4) 表示设置了4个worker来执行整个topology的所有组件</span><br><span class="line"></span><br><span class="line">builder.setBolt(&quot;boltA&quot;,new BoltA(),  4)  ----&gt;指明 boltA组件的线程数excutors总共有4个</span><br><span class="line">builder.setBolt(&quot;boltB&quot;,new BoltB(),  4) ----&gt;指明 boltB组件的线程数excutors总共有4个</span><br><span class="line">builder.setSpout(&quot;randomSpout&quot;,new RandomSpout(),  2) ----&gt;指明randomSpout组件的线程数excutors总共有4个</span><br><span class="line"></span><br><span class="line">-----意味着整个topology中执行所有组件的总线程数为4+4+2=10个</span><br><span class="line">----worker数量是4个，有可能会出现这样的负载情况，  worker-1有2个线程，worker-2有2个线程，worker-3有3个线程，worker-4有3个线程</span><br><span class="line"></span><br><span class="line">如果指定某个组件的具体task并发实例数</span><br><span class="line">builder.setSpout(&quot;randomspout&quot;, new RandomWordSpout(), 4).setNumTasks(8);</span><br><span class="line">----意味着对于这个组件的执行线程excutor来说，一个excutor将执行8/4=2个task</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>【课件】<br> <a href="F:[阶段18]Hadoop大数据\weekend110-第7天\其他打包（解压我即可）\其他打包\storm-trainning-v1.0-zs.ppt">storm-trainning-v1.0-zs.ppt</a> </p>
<h3 id="停止Topologies"><a href="#停止Topologies" class="headerlink" title="停止Topologies"></a><strong>停止Topologies</strong></h3><p>查看当前运行的topo： storm list</p>
<p>命令格式：storm kill 【拓扑名称】</p>
<p>样例：storm kill wordcountTop</p>
<p>杀掉wordcountTop拓扑。</p>
<p>storm的深入学习：<br>            分布式共享锁的实现<br>            事务topology的实现机制及开发模式<br>            在具体场景中的跟其他框架的整合（flume/activeMQ/kafka(分布式的消息队列系统)       /redis/hbase/mysql cluster）</p>
<h1 id="七、Kafka"><a href="#七、Kafka" class="headerlink" title="七、Kafka"></a>七、Kafka</h1><p><img src="http://img.mxranger.cn/Hadoop/1553150270433.png" alt="1553150270433"></p>
<h2 id="1、介绍-4"><a href="#1、介绍-4" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>1、kafka是一个分布式的消息缓存系统<br>2、kafka集群中的服务器都叫做broker<br>3、kafka有两类客户端，一类叫producer（消息生产者），一类叫做consumer（消息消费者），客户端和     broker服务器之间采用tcp协议连接<br>4、kafka中不同业务系统的消息可以通过topic进行区分，而且每一个消息topic都会被分区，以分担消息读写的负载<br>5、每一个分区都可以有多个副本，以防止数据的丢失<br>6、某一个分区中的数据如果需要更新，都必须通过该分区所有副本中的leader来更新<br>7、消费者可以分组，比如有两个消费者组A和B，共同消费一个topic：order_info,A和B所消费的消息不会重复<br>比如 order_info 中有100个消息，每个消息有一个id,编号从0-99，那么，如果A组消费0-49号，B组就消费50-99号（不一定连续）<br>8、消费者在具体消费某个topic中的消息时，可以指定起始偏移量</p>
<h2 id="2、使用"><a href="#2、使用" class="headerlink" title="2、使用"></a>2、使用</h2><h3 id="1、单机模式"><a href="#1、单机模式" class="headerlink" title="1、单机模式"></a>1、单机模式</h3><p>1、解压文件<a href="C:\Users\MxRanger\Desktop\kafka_2.11-2.1.0.tgz">kafka_2.11-2.1.0.tgz</a> </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; tar -xzf kafka_2.11-2.1.0.tgz``&gt; ``cd` `kafka_2.11-2.1.0`</span><br></pre></td></tr></table></figure>

<p>2、自带zookeeper</p>
<p>Kafka uses ZooKeeper so you need to first start a ZooKeeper server if you don’t already have one. You can use the convenience script packaged with kafka to get a quick-and-dirty single-node ZooKeeper instance.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; bin/zookeeper-server-start.sh config/zookeeper.properties</span><br></pre></td></tr></table></figure>

<p>3、创建一个topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">创建</span><br><span class="line">&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span><br><span class="line">查看</span><br><span class="line">&gt; bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure>

<p>4、发送接收消息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">开启生产者</span><br><span class="line">&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</span><br><span class="line">开启消费者</span><br><span class="line">&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</span><br></pre></td></tr></table></figure>

<p><img src="http://img.mxranger.cn/Hadoop/kafka.gif" alt="kafka"></p>
<h3 id="2、集群模式"><a href="#2、集群模式" class="headerlink" title="2、集群模式"></a>2、集群模式</h3><p>1、启动zookeeper集群【<a href="#1%E3%80%81zookeeper%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85">跳转</a>】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zookeeper/bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>2、准备三台机器，各自修改<code>config/server.properties</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[server.properties]</span><br><span class="line">	broker.id=0		//三台机，分别为0,1,2</span><br><span class="line">	log.dirs=/tmp/kafka-logs</span><br><span class="line">	zookeeper.connect=master:2181,slave1:2181,slave2:2181</span><br></pre></td></tr></table></figure>

<p>同时启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./kafka/bin/kafka-server-start.sh kafka/config/server.properties &amp;</span><br></pre></td></tr></table></figure>

<p>3、创建topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic</span><br></pre></td></tr></table></figure>

<p>4、命令方式开启生产者消费者</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">生产者</span><br><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic</span><br><span class="line">消费者</span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic</span><br></pre></td></tr></table></figure>

<p><img src="http://img.mxranger.cn/Hadoop/kafka-1553177521487.gif" alt="kafka"></p>
<h3 id="3、使用Java进行编写生产者、消费者"><a href="#3、使用Java进行编写生产者、消费者" class="headerlink" title="3、使用Java进行编写生产者、消费者"></a>3、使用Java进行编写生产者、消费者</h3><p>1、pom.xml引包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients --&gt;</span><br><span class="line">       &lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">           &lt;version&gt;2.1.0&lt;/version&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">       &lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;</span><br><span class="line">       &lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;</span><br><span class="line">           &lt;version&gt;3.4.13&lt;/version&gt;</span><br><span class="line">           &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2、生产者</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName ProducerDemo</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/21</span></span><br><span class="line"><span class="comment"> * Time      15:44</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;192.168.159.200:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;delivery.timeout.ms&quot;</span>, <span class="number">30001</span>);</span><br><span class="line">        props.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">        props.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">1</span>);</span><br><span class="line">        props.put(<span class="string">&quot;buffer.memory&quot;</span>, <span class="number">33554432</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="comment">//for (int i = 0; i &lt; 100; i++)</span></span><br><span class="line">        producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">&quot;mxranger-cluster&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;i am producer&quot;</span>));</span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>3、消费者</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName ConsumerDemo</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/21</span></span><br><span class="line"><span class="comment"> * Time      15:57</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String topic = <span class="string">&quot;mysons&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Integer threads = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;192.168.159.200:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">&quot;mxranger-cluster&quot;</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line">                System.out.printf(<span class="string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.offset(), record.key(), record.value());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/kafka-cluster.gif" alt="kafka-cluster"></p>
<p>06-kafka  java 客户端</p>
<h1 id="八、Flume日志采集"><a href="#八、Flume日志采集" class="headerlink" title="八、Flume日志采集"></a>八、Flume日志采集</h1><p>监听ip端口的数据</p>
<h3 id="1、使用"><a href="#1、使用" class="headerlink" title="1、使用"></a>1、使用</h3><blockquote>
<p><a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p>
</blockquote>
<p>1、安装解压flume</p>
<p>2、conf文件夹中添加配置文件，保存为demoagent.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> example.conf: A single-node Flume configuration</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = master</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>3、flume文件夹下启动命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent --conf conf --conf-file conf/demoagent.conf --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>4、打开windos的cmd</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">telnet 192.168.159.200 44444</span><br></pre></td></tr></table></figure>

<p>5、实时采集</p>
<p><img src="http://img.mxranger.cn/Hadoop/flume.gif" alt="flume"></p>
<h1 id="九、运营商流量日志解析增强"><a href="#九、运营商流量日志解析增强" class="headerlink" title="九、运营商流量日志解析增强"></a>九、运营商流量日志解析增强</h1><h2 id="1、采集"><a href="#1、采集" class="headerlink" title="1、采集"></a>1、采集</h2><p>不多说</p>
<h2 id="2、使用MapReduce做流量统计"><a href="#2、使用MapReduce做流量统计" class="headerlink" title="2、使用MapReduce做流量统计"></a>2、使用MapReduce做流量统计</h2><h3 id="1、流量数据如下："><a href="#1、流量数据如下：" class="headerlink" title="1、流量数据如下："></a>1、流量数据如下：</h3><p><img src="index_files/1553351527245.png" alt="1553351527245"></p>
<p>步骤与 [流量统计案例](# 3、流量统计案例)类似，但是在排序的时候利用的是TreeMap进行对key排序，不需要二次MR</p>
<h3 id="2、MR代码如下："><a href="#2、MR代码如下：" class="headerlink" title="2、MR代码如下："></a>2、MR代码如下：</h3><p>1、TopkUrlMapper</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowtopkurl;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName TopkUrlMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/23</span></span><br><span class="line"><span class="comment"> * Time      15:56</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TopkUrlMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>,<span class="title">Text</span>, <span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> FlowBean flowBean;</span><br><span class="line">    <span class="keyword">private</span> Text k ;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String line = value.toString();</span><br><span class="line"></span><br><span class="line">        String[] fields = StringUtils.split(line, <span class="string">&#x27;\t&#x27;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(fields.length &gt; <span class="number">32</span> &amp;&amp; StringUtils.isNotEmpty(fields[<span class="number">26</span>])</span><br><span class="line">                &amp;&amp; fields[<span class="number">26</span>].startsWith(<span class="string">&quot;http&quot;</span>))&#123;</span><br><span class="line"></span><br><span class="line">                String url = fields[<span class="number">26</span>];</span><br><span class="line"></span><br><span class="line">                <span class="keyword">long</span> up_flow = Long.parseLong(fields[<span class="number">30</span>]);</span><br><span class="line">                <span class="keyword">long</span> down_flow = Long.parseLong(fields[<span class="number">31</span>]);</span><br><span class="line"></span><br><span class="line">                flowBean = <span class="keyword">new</span> FlowBean(<span class="string">&quot;&quot;</span>, up_flow, down_flow);</span><br><span class="line"></span><br><span class="line">                k = <span class="keyword">new</span> Text();</span><br><span class="line">                k.set(url);</span><br><span class="line">                context.write(k,flowBean);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="comment">/*catch (NumberFormatException e1)&#123;</span></span><br><span class="line"><span class="comment">            e1.printStackTrace();</span></span><br><span class="line"><span class="comment">            System.out.println(&quot;url::&quot;+fields[26]);</span></span><br><span class="line"><span class="comment">        &#125;*/</span><span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;exception occured in mapper&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*    public boolean isURL(String url)&#123;</span></span><br><span class="line"><span class="comment">        String regex = &quot;^([hH][tT]&#123;2&#125;[pP]:/*|[hH][tT]&#123;2&#125;[pP][sS]:/*|[fF][tT][pP]:/*)(([A-Za-z0-9-~]+).)+&quot; +</span></span><br><span class="line"><span class="comment">                &quot;([A-Za-z0-9-~\\/])+(\\?&#123;0,1&#125;(([A-Za-z0-9-~]+\\=&#123;0,1&#125;)([A-Za-z0-9-~]*)\\&amp;&#123;0,1&#125;)*)$&quot;;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">        Pattern pattern = Pattern.compile(regex);</span></span><br><span class="line"><span class="comment">        if (pattern.matcher(url).matches()) &#123;</span></span><br><span class="line"><span class="comment">            return true;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        return false;</span></span><br><span class="line"><span class="comment">    &#125;*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2、TopkUrlReducer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowtopkurl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.TreeMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName TopkUrlMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/23</span></span><br><span class="line"><span class="comment"> * Time      15:56</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TopkUrlReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">FlowBean</span>,<span class="title">Text</span>, <span class="title">LongWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TreeMap&lt;FlowBean,String&gt; treeMap = <span class="keyword">new</span> TreeMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">double</span> globalCount;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//&lt;url , &#123;bean,bean,bean,......&#125;&gt;</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String url = key.toString();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> up_flow = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">long</span> down_flow = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (FlowBean flowBean : values)&#123;</span><br><span class="line">            up_flow += flowBean.getUp_flow();</span><br><span class="line">            down_flow += flowBean.getDown_flow();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        FlowBean bean = <span class="keyword">new</span> FlowBean(<span class="string">&quot;&quot;</span>,up_flow,down_flow);</span><br><span class="line">        <span class="comment">//每求得一条url的总流量，就累加到全局流量计数器中，等所有的记录处理完成后，globalCount中的值就是全局的流量总和</span></span><br><span class="line">        globalCount += bean.getSum_flow();</span><br><span class="line">        treeMap.put(bean,url);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//cleanup方法是在reduer任务即将退出时被调用一次</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        Set&lt;Map.Entry&lt;FlowBean, String&gt;&gt; entrySet = treeMap.entrySet();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> tempCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;FlowBean, String&gt; ent : entrySet)&#123;</span><br><span class="line">            <span class="keyword">if</span> (tempCount / globalCount &lt; <span class="number">0.8</span>)&#123;</span><br><span class="line"></span><br><span class="line">                context.write(<span class="keyword">new</span> Text(ent.getValue()),<span class="keyword">new</span> LongWritable(ent.getKey().getSum_flow()));</span><br><span class="line">                tempCount += ent.getKey().getSum_flow();</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3、Runner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowtopkurl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName TopkUrlMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/23</span></span><br><span class="line"><span class="comment"> * Time      15:56</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TopkUrlRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] strings)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 远程服务器执行  不指定远程的东西，默认是本地的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://master:9000/&quot;</span>);</span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">        <span class="comment">//将jar包扔上去</span></span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.job.jar&quot;</span>, <span class="string">&quot;target/HadoopProject-1.0-SNAPSHOT.jar&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.framework.name&quot;</span>, <span class="string">&quot;yarn&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;yarn.resourcemanager.hostname&quot;</span>, <span class="string">&quot;master&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.app-submission.cross-platform&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(TopkUrlRunner.class);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(TopkUrlMapper.class);</span><br><span class="line">        job.setReducerClass(TopkUrlReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job,<span class="string">&quot;/flowtopkurl/http.log&quot;</span>);</span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> Path(<span class="string">&quot;/flowtopkurl/out&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span>:<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> run = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> TopkUrlRunner(), args);</span><br><span class="line">            System.exit(run);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553351865495.png" alt="1553351865495"></p>
<h2 id="3、利用sqoop将统计结果导入mysql"><a href="#3、利用sqoop将统计结果导入mysql" class="headerlink" title="3、利用sqoop将统计结果导入mysql"></a>3、利用sqoop将统计结果导入mysql</h2><h3 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h3><blockquote>
<p>—-sqoop是一个用来在hadoop体系和关系型数据库之间进行数据互导的工具<br>—-实质就是将导入导出命令转换成mapreduce程序来实现</p>
<p>[简单使用](# 3.sqoop的使用)</p>
</blockquote>
<p>1、解压sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz </p>
<p>2、修改配置文件 conf文件夹下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sqoop-env.sh</span><br><span class="line">#Set path to where bin/hadoop is available</span><br><span class="line">export HADOOP_COMMON_HOME=/usr/local/hadoop</span><br><span class="line"></span><br><span class="line">#Set path to where hadoop-*-core.jar is available</span><br><span class="line">export HADOOP_MAPRED_HOME=/usr/local/hadoop</span><br><span class="line"></span><br><span class="line">#set the path to where bin/hbase is available</span><br><span class="line">#export HBASE_HOME=</span><br><span class="line"></span><br><span class="line">#Set the path to where bin/hive is available</span><br><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line"></span><br><span class="line">#Set the path for where zookeper config dir is</span><br><span class="line">export ZOOCFGDIR=/root/env/zookeeper</span><br></pre></td></tr></table></figure>

<p>3、将mysql驱动包放入lib文件夹里，进入bin目录，输入命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqoop export --connect jdbc:mysql://192.168.159.100:3306/urlcontentanalyse --username root --password 1234 \</span><br><span class="line">--table urlrule \</span><br><span class="line">--export-dir /flowtopkurl/out/part-r-00000 \</span><br><span class="line">--columns url \</span><br><span class="line">--input-fields-terminated-by &#x27;\t&#x27;</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<p><img src="http://img.mxranger.cn/Hadoop/1553352087653.png" alt="1553352087653"></p>
<h2 id="4、将日志数据增强"><a href="#4、将日志数据增强" class="headerlink" title="4、将日志数据增强"></a>4、将日志数据增强</h2><p>​    读入原始日志数据，抽取其中的url，查询规则库，获得该url指向的网页内容的分析结果，追加到原始日志后</p>
<p>​    首先将mysql的数据存到HashMap中，读取http.log流量运营日志文件，利用日志文件中的url去hashmap中读取，若查询不到结果，则追加日志<code>tocrawl</code>（待爬）</p>
<p>​    由于本次操作在Map中就可运行，所以不需要Reduce，但是需要重写FileOutputFormat方法，根据是否需要待爬的日志分为两个文件，若不要待爬，则存入enhancedLog文件中，否则存入tocrawl文件中</p>
<p>具体代码如下：</p>
<p>1、jdbc读取内容</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowtopkurl.enhance;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.ResultSet;</span><br><span class="line"><span class="keyword">import</span> java.sql.Statement;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DBLoader</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dbLoader</span><span class="params">(HashMap&lt;String, String&gt; ruleMap)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">		Connection conn = <span class="keyword">null</span>;</span><br><span class="line">		Statement st = <span class="keyword">null</span>;</span><br><span class="line">		ResultSet res = <span class="keyword">null</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line">			conn = DriverManager.getConnection(<span class="string">&quot;jdbc:mysql://192.168.159.100:3306/urlcontentanalyse&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;1234&quot;</span>);</span><br><span class="line">			st = conn.createStatement();</span><br><span class="line">			res = st.executeQuery(<span class="string">&quot;select url,info from urlrule&quot;</span>);</span><br><span class="line">			<span class="keyword">while</span> (res.next()) &#123;</span><br><span class="line">				ruleMap.put(res.getString(<span class="number">1</span>), <span class="string">&quot;itiscomplete&quot;</span>);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			</span><br><span class="line">		&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">			<span class="keyword">try</span>&#123;</span><br><span class="line">				<span class="keyword">if</span>(res!=<span class="keyword">null</span>)&#123;</span><br><span class="line">					res.close();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span>(st!=<span class="keyword">null</span>)&#123;</span><br><span class="line">					st.close();</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span>(conn!=<span class="keyword">null</span>)&#123;</span><br><span class="line">					conn.close();</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">			&#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		DBLoader db = <span class="keyword">new</span> DBLoader();</span><br><span class="line">		HashMap&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String,String&gt;();</span><br><span class="line">		db.dbLoader(map);</span><br><span class="line">		System.out.println(map.size());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2、mapper</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowtopkurl.enhance;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> scala.xml.Null;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName LogEnhanceMapper</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/23</span></span><br><span class="line"><span class="comment"> * Time      21:31</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读入原始日志数据，抽取其中的url，查询规则库，获得该url指向的网页内容的分析结果，追加到原始日志后</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//读入原始数据47个字段   时间戳</span></span><br><span class="line"><span class="comment">//抽取其中的url查询规则库得到众多的内容识别信息 网站类别，频道类别，主题词，关键词，影片名，主演，导演</span></span><br><span class="line"><span class="comment">//将分析结构主驾到原始日志后面</span></span><br><span class="line"><span class="comment">//如果某条url在规则库中查不到结果，则输出到待爬清单</span></span><br><span class="line"><span class="comment">// context.write(url  , tocrawl)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEnhanceMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>,<span class="title">Text</span>, <span class="title">NullWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String,String&gt; ruleMap;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//setup方法是在mapper task初始化时被调用一次</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        ruleMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        DBLoader.dbLoader(ruleMap);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String line = value.toString();</span><br><span class="line"></span><br><span class="line">        String[] fields = StringUtils.split(line,<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">        String url = fields[<span class="number">26</span>];</span><br><span class="line"></span><br><span class="line">        String info = ruleMap.get(url);</span><br><span class="line">        String result = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">if</span>(info != <span class="keyword">null</span>)&#123;</span><br><span class="line">            result = line + <span class="string">&quot;\t&quot;</span> + info;</span><br><span class="line">            context.write(<span class="keyword">new</span> Text(result), NullWritable.get());</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            result = url + <span class="string">&quot;\t&quot;</span> + <span class="string">&quot;tocrawl&quot;</span>;</span><br><span class="line">            context.write(<span class="keyword">new</span> Text(result), NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3、重写OutputFormat</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.mxranger.flowtopkurl.enhance;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName LogEnhanceOutputFormat</span></span><br><span class="line"><span class="comment"> * Author    MxRanger</span></span><br><span class="line"><span class="comment"> * Date      2019/3/23</span></span><br><span class="line"><span class="comment"> * Time      22:11</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEnhanceOutputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">FileOutputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RecordWriter&lt;K, V&gt; <span class="title">getRecordWriter</span><span class="params">(TaskAttemptContext job)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        FileSystem fs = FileSystem.get(<span class="keyword">new</span> Configuration());</span><br><span class="line">        FSDataOutputStream enhancedOs = fs.create(<span class="keyword">new</span> Path(<span class="string">&quot;/liuliang/output/enhancedLog&quot;</span>));</span><br><span class="line">        FSDataOutputStream tocrawlOs = fs.create(<span class="keyword">new</span> Path(<span class="string">&quot;/liuliang/output/tocrawl&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> LogEnhanceRecordWriter&lt;K, V&gt;(enhancedOs,tocrawlOs);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEnhanceRecordWriter</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">RecordWriter</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt;</span>&#123;</span><br><span class="line">        <span class="keyword">private</span> FSDataOutputStream enhancedOs =<span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">private</span> FSDataOutputStream tocrawlOs =<span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">LogEnhanceRecordWriter</span><span class="params">(FSDataOutputStream enhancedOs,FSDataOutputStream tocrawlOs)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">this</span>.enhancedOs = enhancedOs;</span><br><span class="line">            <span class="keyword">this</span>.tocrawlOs = tocrawlOs;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(K key, V value)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">                InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(key.toString().contains(<span class="string">&quot;tocrawl&quot;</span>))&#123;</span><br><span class="line">                tocrawlOs.write(key.toString().getBytes());</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                enhancedOs.write(key.toString().getBytes());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">                InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(enhancedOs != <span class="keyword">null</span>)&#123;</span><br><span class="line">                enhancedOs.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(tocrawlOs != <span class="keyword">null</span>)&#123;</span><br><span class="line">                tocrawlOs.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="3-sqoop的使用"><a href="#3-sqoop的使用" class="headerlink" title="3.sqoop的使用"></a>3.sqoop的使用</h5><pre><code>    第一类：数据库中的数据导入到HDFS上
        sqoop import 
        --connect jdbc:mysql://192.168.1.10:3306/itcast 
        --username root --password 123  
        --table trade_detail 
        --columns &#39;id, account, income, expenses&#39;
    指定输出路径、指定数据分隔符
    sqoop import 
    --connect jdbc:mysql://192.168.1.10:3306/itcast 
    --username root --password 123  
    ##要导入数据的表
    --table trade_detail 
    ##数据导入hdfs后所存放的目录
    --target-dir &#39;/sqoop/td&#39; 
    ##导入的数据字段之间的分隔符
    --fields-terminated-by &#39;\t&#39;
    
    指定Map数量 -m 
    sqoop import 
    --connect jdbc:mysql://192.168.1.10:3306/itcast 
    --username root --password 123  
    --table trade_detail 
    --target-dir &#39;/sqoop/td1&#39; 
    --fields-terminated-by &#39;\t&#39;
    ##指定做导入处理时的map 任务数 
    -m 2

    增加where条件, 注意：条件必须用引号引起来
    sqoop import 
    --connect jdbc:mysql://192.168.1.10:3306/itcast 
    --username root --password 123  
    --table trade_detail 
    --where &#39;id&gt;3&#39; 
    --target-dir &#39;/sqoop/td2&#39; 

    增加query语句(使用 \ 将语句换行)
    sqoop import 
    --connect jdbc:mysql://192.168.1.10:3306/itcast 
    --username root --password 123 
    --query &#39;SELECT * FROM trade_detail where id &gt; 2 AND $CONDITIONS&#39; 
    --split-by trade_detail.id 
    --target-dir &#39;/sqoop/td3&#39;
    
    注意：如果使用--query这个命令的时候，需要注意的是where后面的参数，AND $CONDITIONS这个参数必须加上
    而且存在单引号与双引号的区别，如果--query后面使用的是双引号，那么需要在$CONDITIONS前加上\即\$CONDITIONS
    如果设置map数量为1个时即-m 1，不用加上--split-by $&#123;tablename.column&#125;，否则需要加上
    
第二类：将HDFS上的文件数据导出到数据库的表里面去
    sqoop export 
    --connect jdbc:mysql://192.168.8.120:3306/itcast 
    --username root --password 123 
    ##你要导出的数据所在的目录
    --export-dir &#39;/td3&#39; 
    ##你要导往的目标关系表
    --table td_bak 
    -m 1 
    ##你要导出的文件的字段分隔符
    --fields-termianted-by &#39;\t&#39;
</code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">慕·歌</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2019/04/30/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/">http://example.com/2019/04/30/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">MxRanger's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="/images/hadoop.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/04/30/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/"><img class="prev-cover" src="http://img.mxranger.cn/Spark/spark-stack.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Spark使用</div></div></a></div><div class="next-post pull-right"><a href="/2019/04/01/back/SpringBoot%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/"><img class="next-cover" src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1580736024802&amp;di=a53178dace5fdaf4f3da4da5d95fb085&amp;imgtype=0&amp;src=http%3A%2F%2Fpic.51yuansu.com%2Fpic3%2Fcover%2F02%2F43%2F06%2F59e4ba7460114_610.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">SpringBoot发送邮件</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/images/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">慕·歌</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/GavinGrayer"><i class="fas fa-bookmark"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:mxranger@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">守的云开见明月, 做时间的朋友</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81Hadoop"><span class="toc-text">一、Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81HDFS-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-text">1、HDFS 实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%8E%9F%E7%90%86%E5%9B%BE%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-text">1、原理图如下：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%B8%B8%E7%94%A8%E7%9A%84shell%E5%91%BD%E4%BB%A4"><span class="toc-text">2、常用的shell命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81HDFS%E7%9A%84block%E5%88%87%E7%89%87%E4%B8%BA128M%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-text">3、HDFS的block切片为128M的原因</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88HDFS%E4%B8%AD%E5%9D%97%EF%BC%88block%EF%BC%89%E4%B8%8D%E8%83%BD%E8%AE%BE%E7%BD%AE%E5%A4%AA%E5%A4%A7%EF%BC%8C%E4%B9%9F%E4%B8%8D%E8%83%BD%E8%AE%BE%E7%BD%AE%E5%A4%AA%E5%B0%8F%EF%BC%9F"><span class="toc-text">1、为什么HDFS中块（block）不能设置太大，也不能设置太小？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81-HDFS%E4%B8%AD%E5%9D%97%EF%BC%88block%EF%BC%89%E7%9A%84%E5%A4%A7%E5%B0%8F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AE%BE%E7%BD%AE%E4%B8%BA128M%EF%BC%9F"><span class="toc-text">2、 HDFS中块（block）的大小为什么设置为128M？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81HDFS-%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84"><span class="toc-text">4、HDFS 存储架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1%E3%80%81namenode%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-text">3.1、namenode工作原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E3%80%81%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%BB%86%E8%8A%82"><span class="toc-text">1、元数据存储细节</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E3%80%81%E5%85%83%E6%95%B0%E6%8D%AE%E5%8E%9F%E7%90%86%E6%9C%BA%E5%88%B6"><span class="toc-text">1、元数据原理机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%E3%80%81%E8%AF%BB%E8%AF%B7%E6%B1%82"><span class="toc-text">2、读请求</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%E3%80%81%E5%86%99%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B"><span class="toc-text">3、写请求过程</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2%E3%80%81SecondaryNameNode%E5%90%88%E5%B9%B6%E6%9C%BA%E5%88%B6"><span class="toc-text">3.2、SecondaryNameNode合并机制</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E3%80%81secondary-namenode%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%9A"><span class="toc-text">1、secondary namenode的工作流程：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%E3%80%81%E4%BD%95%E6%97%B6checkpoint"><span class="toc-text">2、何时checkpoint</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3%E3%80%81datanode%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-text">3.3、datanode工作原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E4%BD%BF%E7%94%A8JAVA%E8%BF%9B%E8%A1%8CHDFS%E7%BC%96%E7%A8%8B"><span class="toc-text">2、使用JAVA进行HDFS编程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81maven%E5%BC%95%E5%8C%85"><span class="toc-text">1、maven引包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81CRUD"><span class="toc-text">2、CRUD</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC"><span class="toc-text">1、读取文本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span class="toc-text">2、创建目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E3%80%81%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95"><span class="toc-text">3、删除文件或目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E3%80%81%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6"><span class="toc-text">4、上传文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%E3%80%81%E6%9F%A5%E7%9C%8B%E7%9B%AE%E5%BD%95%E5%88%97%E8%A1%A8"><span class="toc-text">5、查看目录列表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81RPC%E6%A1%86%E6%9E%B6%E6%80%9D%E6%83%B3"><span class="toc-text">3、RPC框架思想</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%EF%BC%9A"><span class="toc-text">应用：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4%E3%80%81MapReduce"><span class="toc-text">4、MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81WordCount%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B"><span class="toc-text">1、WordCount工作过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%88%86%E8%AF%8D%E7%BB%9F%E8%AE%A1"><span class="toc-text">2、分词统计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89Map%E5%92%8CReduce"><span class="toc-text">1、自定义Map和Reduce</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E7%BB%9F%E8%AE%A1%E6%96%B9%E5%BC%8F"><span class="toc-text">2、统计方式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E3%80%901%E3%80%91%E6%9C%AC%E5%9C%B0%E8%84%B1%E7%A6%BBhdfs%E7%8B%AC%E7%AB%8B%E8%BF%90%E8%A1%8CMR"><span class="toc-text">【1】本地脱离hdfs独立运行MR</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E3%80%902%E3%80%91%E6%8B%89%E5%8F%96hdfs%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%EF%BC%8C%E7%84%B6%E5%90%8E%E5%9C%A8%E4%BF%9D%E5%AD%98%E5%88%B0hdfs"><span class="toc-text">【2】拉取hdfs文件到本地运行，然后在保存到hdfs</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E3%80%903%E3%80%91%E8%BF%9C%E7%A8%8B%E4%BD%BF%E7%94%A8MR"><span class="toc-text">【3】远程使用MR</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E4%BD%BF%E7%94%A8Maven%E8%BF%90%E8%A1%8CMR"><span class="toc-text">3、使用Maven运行MR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E6%B5%81%E9%87%8F%E7%BB%9F%E8%AE%A1%E6%A1%88%E4%BE%8B"><span class="toc-text">3、流量统计案例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89Map%E5%92%8CReduce-1"><span class="toc-text">1、自定义Map和Reduce</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E3%80%81%E4%BC%A0%E8%BE%93%E5%AF%B9%E8%B1%A1FlowBean"><span class="toc-text">1、传输对象FlowBean</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%E3%80%81FlowSumMapper"><span class="toc-text">2、FlowSumMapper</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%E3%80%81FlowSumReducer"><span class="toc-text">3、FlowSumReducer</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4%E3%80%81FlowSumRunner%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F"><span class="toc-text">4、FlowSumRunner远程执行方式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5%E3%80%81FlowSumCmdRunner%EF%BC%88%E5%91%BD%E4%BB%A4%E6%96%B9%E5%BC%8F%EF%BC%89"><span class="toc-text">5、FlowSumCmdRunner（命令方式）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6%E3%80%81%E6%89%93%E5%8C%85%E4%B8%8A%E4%BC%A0"><span class="toc-text">6、打包上传</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%92%E5%BA%8F%EF%BC%88%E4%BA%8C%E6%AC%A1MR%EF%BC%89"><span class="toc-text">2、流量排序（二次MR）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E3%80%81%E4%BC%A0%E8%BE%93%E5%AF%B9%E8%B1%A1FlowBean-1"><span class="toc-text">1、传输对象FlowBean</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%E3%80%81SortCMDMR"><span class="toc-text">2、SortCMDMR</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%E3%80%81%E6%89%93%E5%8C%85%E4%B8%8A%E4%BC%A0"><span class="toc-text">3、打包上传</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E7%BB%84"><span class="toc-text">3、自定义分组</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E3%80%81AreaPartitioner"><span class="toc-text">1、AreaPartitioner</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89MR"><span class="toc-text">2、自定义MR</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Zookeeper"><span class="toc-text">二、Zookeeper</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E4%BB%8B%E7%BB%8D"><span class="toc-text">1、介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E8%8A%82%E7%82%B9"><span class="toc-text">1、节点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E6%80%BB%E7%BB%93"><span class="toc-text">2、总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81HA"><span class="toc-text">三、HA</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Hive"><span class="toc-text">四、Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E4%BB%8B%E7%BB%8D-1"><span class="toc-text">1、介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E5%AE%89%E8%A3%85"><span class="toc-text">2、安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8MySQL%E5%81%9AHive%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-text">使用MySQL做Hive的元数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF"><span class="toc-text">常见错误</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%80%901%E3%80%91%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E6%8A%A5%E9%94%99SemanticException-org-apache-hadoop-hive-ql-metadata-HiveException"><span class="toc-text">【1】执行sql语句报错SemanticException org.apache.hadoop.hive.ql.metadata.HiveException</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%80%902%E3%80%91%E5%88%9B%E5%BB%BA%E8%A1%A8%E6%8A%A5%E9%94%99Column-length-too-big-for-column-%E2%80%98PARAM-VALUE%E2%80%99-max-21845-use-BLOB-or-Text-instead"><span class="toc-text">【2】创建表报错Column length too big for column ‘PARAM_VALUE’(max&#x3D;21845); use BLOB or Text instead</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mysql%E5%AD%98%E5%82%A8%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE"><span class="toc-text">mysql存储的元数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81hive%E4%BD%BF%E7%94%A8"><span class="toc-text">3、hive使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E8%87%AA%E5%88%B6%E6%96%87%E6%9C%AC"><span class="toc-text">1、自制文本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81hive%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93test%EF%BC%8C%E5%88%9B%E5%BB%BA%E8%A1%A8phone%EF%BC%8C%E5%AF%BC%E5%85%A5%E6%96%87%E6%9C%AC%E5%86%85%E5%AE%B9"><span class="toc-text">2、hive创建数据库test，创建表phone，导入文本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E8%AE%A1%E7%AE%97%E6%80%BB%E6%95%B0"><span class="toc-text">3、计算总数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81HBase"><span class="toc-text">五、HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E4%BB%8B%E7%BB%8D-2"><span class="toc-text">1、介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HBase%E8%A1%A8%E7%BB%93%E6%9E%84"><span class="toc-text">HBase表结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E5%AE%89%E8%A3%85-1"><span class="toc-text">2、安装</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD%E3%80%81Storm"><span class="toc-text">六、Storm</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E4%BB%8B%E7%BB%8D-3"><span class="toc-text">1、介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E5%AE%89%E8%A3%85-2"><span class="toc-text">2、安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81zookeeper%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85"><span class="toc-text">1、zookeeper集群安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81storm%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-text">2、storm集群搭建</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81%E4%BD%BF%E7%94%A8"><span class="toc-text">3、使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%B0%B4%E9%BE%99%E5%A4%B4Spout%EF%BC%88%E6%B5%81%E5%85%A5%E5%8F%A3%EF%BC%89"><span class="toc-text">1、水龙头Spout（流入口）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%A4%84%E7%90%86blot"><span class="toc-text">2、处理blot</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81UpperBolt%E8%BD%AC%E6%88%90%E5%A4%A7%E5%86%99"><span class="toc-text">1、UpperBolt转成大写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81SuffixBolt-%E5%8A%A0%E5%90%8E%E7%BC%80"><span class="toc-text">2、SuffixBolt 加后缀</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E4%B8%BB%E5%87%BD%E6%95%B0"><span class="toc-text">3、主函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81%E6%89%93%E5%8C%85jar"><span class="toc-text">4、打包jar</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4%E3%80%81Storm%E4%B8%8EHadoop%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-text">4、Storm与Hadoop的对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5%E3%80%81Storm%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-text">5、Storm体系结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6%E3%80%81%E6%80%BB%E7%BB%93"><span class="toc-text">6、总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%9C%E6%AD%A2Topologies"><span class="toc-text">停止Topologies</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83%E3%80%81Kafka"><span class="toc-text">七、Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E4%BB%8B%E7%BB%8D-4"><span class="toc-text">1、介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E4%BD%BF%E7%94%A8"><span class="toc-text">2、使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F"><span class="toc-text">1、单机模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F"><span class="toc-text">2、集群模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E4%BD%BF%E7%94%A8Java%E8%BF%9B%E8%A1%8C%E7%BC%96%E5%86%99%E7%94%9F%E4%BA%A7%E8%80%85%E3%80%81%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-text">3、使用Java进行编写生产者、消费者</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB%E3%80%81Flume%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86"><span class="toc-text">八、Flume日志采集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E4%BD%BF%E7%94%A8"><span class="toc-text">1、使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E8%BF%90%E8%90%A5%E5%95%86%E6%B5%81%E9%87%8F%E6%97%A5%E5%BF%97%E8%A7%A3%E6%9E%90%E5%A2%9E%E5%BC%BA"><span class="toc-text">九、运营商流量日志解析增强</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E9%87%87%E9%9B%86"><span class="toc-text">1、采集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E4%BD%BF%E7%94%A8MapReduce%E5%81%9A%E6%B5%81%E9%87%8F%E7%BB%9F%E8%AE%A1"><span class="toc-text">2、使用MapReduce做流量统计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%B5%81%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-text">1、流量数据如下：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81MR%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-text">2、MR代码如下：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81%E5%88%A9%E7%94%A8sqoop%E5%B0%86%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%9C%E5%AF%BC%E5%85%A5mysql"><span class="toc-text">3、利用sqoop将统计结果导入mysql</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sqoop"><span class="toc-text">sqoop</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4%E3%80%81%E5%B0%86%E6%97%A5%E5%BF%97%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-text">4、将日志数据增强</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-sqoop%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">3.sqoop的使用</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/06/19/hello-world/" title="Hello World"><img src="http://img.mxranger.cn/gratisography-370H.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2021/06/19/hello-world/" title="Hello World">Hello World</a><time datetime="2021-06-19T00:44:25.616Z" title="发表于 2021-06-19 08:44:25">2021-06-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/02/08/back/Vue%E8%84%9A%E6%89%8B%E6%9E%B6%E5%B5%8C%E5%85%A5SpringBoot/" title="Vue脚手架嵌入SpringBoot"><img src="/images/vue%E5%86%85%E5%B5%8Cspringboot.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vue脚手架嵌入SpringBoot"/></a><div class="content"><a class="title" href="/2021/02/08/back/Vue%E8%84%9A%E6%89%8B%E6%9E%B6%E5%B5%8C%E5%85%A5SpringBoot/" title="Vue脚手架嵌入SpringBoot">Vue脚手架嵌入SpringBoot</a><time datetime="2021-02-08T08:35:54.000Z" title="发表于 2021-02-08 16:35:54">2021-02-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/31/front/vue/5%E3%80%81%E7%BB%84%E4%BB%B6%E5%8F%8A%E7%BB%84%E4%BB%B6%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/" title="Vue——组件及组件间的通信"><img src="https://pic1.zhimg.com/v2-a3a350493a1ad6d46a1800ee2aad3fcf_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vue——组件及组件间的通信"/></a><div class="content"><a class="title" href="/2021/01/31/front/vue/5%E3%80%81%E7%BB%84%E4%BB%B6%E5%8F%8A%E7%BB%84%E4%BB%B6%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/" title="Vue——组件及组件间的通信">Vue——组件及组件间的通信</a><time datetime="2021-01-31T12:27:02.000Z" title="发表于 2021-01-31 20:27:02">2021-01-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/31/front/vue/6%E3%80%81%E6%A8%A1%E5%9D%97%E5%8C%96%E5%BC%80%E5%8F%91%E4%B8%8EElmentUI%E7%9A%84%E4%BD%BF%E7%94%A8/" title="Vue——模块化开发与ElmentUI的使用"><img src="https://pic1.zhimg.com/v2-a3a350493a1ad6d46a1800ee2aad3fcf_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vue——模块化开发与ElmentUI的使用"/></a><div class="content"><a class="title" href="/2021/01/31/front/vue/6%E3%80%81%E6%A8%A1%E5%9D%97%E5%8C%96%E5%BC%80%E5%8F%91%E4%B8%8EElmentUI%E7%9A%84%E4%BD%BF%E7%94%A8/" title="Vue——模块化开发与ElmentUI的使用">Vue——模块化开发与ElmentUI的使用</a><time datetime="2021-01-31T12:27:02.000Z" title="发表于 2021-01-31 20:27:02">2021-01-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/31/front/vue/1%E3%80%81Vue%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/" title="Vue——起步"><img src="https://pic1.zhimg.com/v2-a3a350493a1ad6d46a1800ee2aad3fcf_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vue——起步"/></a><div class="content"><a class="title" href="/2021/01/31/front/vue/1%E3%80%81Vue%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/" title="Vue——起步">Vue——起步</a><time datetime="2021-01-31T12:25:02.000Z" title="发表于 2021-01-31 20:25:02">2021-01-31</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/images/hadoop.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By 慕·歌</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="http://blog.mxranger.cn/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      true && mermaid.init()
    })
  }
}</script></div><div class="aplayer no-destroy" data-id="6589190051" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="true" muted></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener toc scroll 
  window.removeEventListener('scroll', window.tocScrollFn)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>